{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bda988b",
   "metadata": {},
   "source": [
    "# Construcción del JSON de referencia J1939-71 para RAG\n",
    "\n",
    "Este cuaderno carga el PDF 'J1939-71.pdf', realiza una extracción básica de texto (para validar acceso al documento) y construye programáticamente el archivo `j1939_71_reference.json` con la estructura consensuada para el RAG y el enlace a DBC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c541d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF existe: True c:\\Users\\henry\\Documents\\GitHub\\Proyecto_Integrador_Grupo7_IBM\\Entrega4_Precision_Semantica_y_Contextualizacion_Eventos_Vehiculares\\J1939-71.pdf\n",
      "Salida JSON en: c:\\Users\\henry\\Documents\\GitHub\\Proyecto_Integrador_Grupo7_IBM\\Entrega4_Precision_Semantica_y_Contextualizacion_Eventos_Vehiculares\\j1939_71_reference.json\n"
     ]
    }
   ],
   "source": [
    "# Rutas de entrada/salida\n",
    "from pathlib import Path\n",
    "PDF_PATH = Path(r'c:\\Users\\henry\\Documents\\GitHub\\Proyecto_Integrador_Grupo7_IBM\\Entrega4_Precision_Semantica_y_Contextualizacion_Eventos_Vehiculares\\J1939-71.pdf')\n",
    "OUTPUT_JSON = Path(r'c:\\Users\\henry\\Documents\\GitHub\\Proyecto_Integrador_Grupo7_IBM\\Entrega4_Precision_Semantica_y_Contextualizacion_Eventos_Vehiculares\\j1939_71_reference.json')\n",
    "\n",
    "print('PDF existe:', PDF_PATH.exists(), str(PDF_PATH))\n",
    "print('Salida JSON en:', str(OUTPUT_JSON))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab7c580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdfplumber versión: 0.11.7\n"
     ]
    }
   ],
   "source": [
    "# Instalar dependencia mínima si hace falta: pdfplumber\n",
    "import importlib, sys, subprocess\n",
    "def ensure_package(pkg):\n",
    "    try:\n",
    "        return importlib.import_module(pkg)\n",
    "    except ImportError:\n",
    "        print(f'Instalando {pkg}...')\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg])\n",
    "        return importlib.import_module(pkg)\n",
    "\n",
    "pdfplumber = ensure_package('pdfplumber')\n",
    "print('pdfplumber versión:', getattr(pdfplumber, '__version__', 'desconocida'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b649b5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Páginas leídas: 3 / 379\n",
      "Previsualización (primeros 500 caracteres):\n",
      "REV.\n",
      "SURFACE J 1939-71 DEC2003\n",
      "®\n",
      "VEHICLE\n",
      "Issued 1994-08\n",
      "RECOMMENDED\n",
      "Revised 2003-12\n",
      "PRACTICE\n",
      "Su perseding J1939-71 AUG2002\n",
      "Vehicle Application Layer — J1939-71 (through December 2001)\n",
      "Foreword\n",
      "This document has also changed to comply with the SAE Technical Standards Board format. Definitions\n",
      "have changed to Section 3 and Abbreviations to Section 4. All other section numbers have changed\n",
      "accordingly. This series of SAE Recommended Practices has been developed by the SAE Truck and\n",
      "Bus Control and \n"
     ]
    }
   ],
   "source": [
    "# Carga básica del PDF y extracción limitada (validación)\n",
    "extracted_preview = ''\n",
    "if PDF_PATH.exists():\n",
    "    with pdfplumber.open(PDF_PATH) as pdf:\n",
    "        pages_to_read = min(3, len(pdf.pages))\n",
    "        texts = []\n",
    "        for i in range(pages_to_read):\n",
    "            txt = pdf.pages[i].extract_text() or ''\n",
    "            texts.append(txt)\n",
    "        extracted_preview = '\\n---\\n'.join(texts)\n",
    "        print(f'Páginas leídas: {pages_to_read} / {len(pdf.pages)}')\n",
    "        print('Previsualización (primeros 500 caracteres):')\n",
    "        print(extracted_preview[:500])\n",
    "else:\n",
    "    print('Advertencia: PDF no encontrado en la ruta indicada.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32765683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\henry\\AppData\\Local\\Temp\\ipykernel_41312\\1902645085.py:112: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now_iso = datetime.datetime.utcnow().replace(microsecond=0).isoformat() + 'Z'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 113\u001b[39m\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m items\n\u001b[32m    112\u001b[39m now_iso = datetime.datetime.utcnow().replace(microsecond=\u001b[32m0\u001b[39m).isoformat() + \u001b[33m'\u001b[39m\u001b[33mZ\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m full_text = \u001b[43mread_pdf_all_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPDF_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m spn_items = parse_spn_blocks(full_text)\n\u001b[32m    115\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mSPNs extraídos:\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(spn_items))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mread_pdf_all_text\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m pdfplumber.open(path) \u001b[38;5;28;01mas\u001b[39;00m pdf:\n\u001b[32m     29\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m pg \u001b[38;5;129;01min\u001b[39;00m pdf.pages:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m             parts.append(\u001b[43mpg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(parts)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pdfplumber\\page.py:530\u001b[39m, in \u001b[36mPage.extract_text\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    529\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_textmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtuplify_list_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.as_string\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pdfplumber\\page.py:507\u001b[39m, in \u001b[36mPage._get_textmap\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    505\u001b[39m     defaults.update({\u001b[33m\"\u001b[39m\u001b[33mlayout_height\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.height})\n\u001b[32m    506\u001b[39m full_kwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] = {**defaults, **kwargs}\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m utils.chars_to_textmap(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchars\u001b[49m, **full_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pdfplumber\\container.py:52\u001b[39m, in \u001b[36mContainer.chars\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchars\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> T_obj_list:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobjects\u001b[49m.get(\u001b[33m\"\u001b[39m\u001b[33mchar\u001b[39m\u001b[33m\"\u001b[39m, [])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pdfplumber\\page.py:346\u001b[39m, in \u001b[36mPage.objects\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_objects\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._objects\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m \u001b[38;5;28mself\u001b[39m._objects: Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._objects\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pdfplumber\\page.py:443\u001b[39m, in \u001b[36mPage.parse_objects\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_objects\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list]:\n\u001b[32m    442\u001b[39m     objects: Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list] = {}\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_layout_objects(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayout\u001b[49m._objs):\n\u001b[32m    444\u001b[39m         kind = obj[\u001b[33m\"\u001b[39m\u001b[33mobject_type\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    445\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m kind \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33manno\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pdfplumber\\page.py:266\u001b[39m, in \u001b[36mPage.layout\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    264\u001b[39m interpreter = PDFPageInterpreter(\u001b[38;5;28mself\u001b[39m.pdf.rsrcmgr, device)\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     \u001b[43minterpreter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpage_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PdfminerException(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pdfminer\\pdfinterp.py:1210\u001b[39m, in \u001b[36mPDFPageInterpreter.process_page\u001b[39m\u001b[34m(self, page)\u001b[39m\n\u001b[32m   1208\u001b[39m     ctm = (\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, -x0, -y0)\n\u001b[32m   1209\u001b[39m \u001b[38;5;28mself\u001b[39m.device.begin_page(page, ctm)\n\u001b[32m-> \u001b[39m\u001b[32m1210\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrender_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mctm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[38;5;28mself\u001b[39m.device.end_page(page)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pdfminer\\pdfinterp.py:1231\u001b[39m, in \u001b[36mPDFPageInterpreter.render_contents\u001b[39m\u001b[34m(self, resources, streams, ctm)\u001b[39m\n\u001b[32m   1229\u001b[39m \u001b[38;5;28mself\u001b[39m.init_resources(resources)\n\u001b[32m   1230\u001b[39m \u001b[38;5;28mself\u001b[39m.init_state(ctm)\n\u001b[32m-> \u001b[39m\u001b[32m1231\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstreams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pdfminer\\pdfinterp.py:1235\u001b[39m, in \u001b[36mPDFPageInterpreter.execute\u001b[39m\u001b[34m(self, streams)\u001b[39m\n\u001b[32m   1233\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, streams: Sequence[\u001b[38;5;28mobject\u001b[39m]) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1235\u001b[39m         parser = \u001b[43mPDFContentParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstreams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m PSEOF:\n\u001b[32m   1237\u001b[39m         \u001b[38;5;66;03m# empty page\u001b[39;00m\n\u001b[32m   1238\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pdfminer\\pdfinterp.py:260\u001b[39m, in \u001b[36mPDFContentParser.__init__\u001b[39m\u001b[34m(self, streams)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m.istream = \u001b[32m0\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;66;03m# PSStackParser.__init__(fp=None) is safe only because we've overloaded\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# all the methods that would attempt to access self.fp without first\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# calling self.fillfp().\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m \u001b[43mPSStackParser\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pdfminer\\psparser.py:538\u001b[39m, in \u001b[36mPSStackParser.__init__\u001b[39m\u001b[34m(self, fp)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, fp: BinaryIO) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m538\u001b[39m     \u001b[43mPSBaseParser\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    539\u001b[39m     \u001b[38;5;28mself\u001b[39m.reset()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pdfminer\\psparser.py:173\u001b[39m, in \u001b[36mPSBaseParser.__init__\u001b[39m\u001b[34m(self, fp)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;28mself\u001b[39m.fp = fp\n\u001b[32m    172\u001b[39m \u001b[38;5;28mself\u001b[39m.eof = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseek\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pdfminer\\pdfinterp.py:272\u001b[39m, in \u001b[36mPDFContentParser.seek\u001b[39m\u001b[34m(self, pos)\u001b[39m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mseek\u001b[39m(\u001b[38;5;28mself\u001b[39m, pos: \u001b[38;5;28mint\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfillfp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m     PSStackParser.seek(\u001b[38;5;28mself\u001b[39m, pos)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pdfminer\\pdfinterp.py:269\u001b[39m, in \u001b[36mPDFContentParser.fillfp\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PSEOF(\u001b[33m\"\u001b[39m\u001b[33mUnexpected EOF, file truncated?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m \u001b[38;5;28mself\u001b[39m.fp = BytesIO(\u001b[43mstrm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pdfminer\\pdftypes.py:404\u001b[39m, in \u001b[36mPDFStream.get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_data\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mbytes\u001b[39m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    406\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pdfminer\\pdftypes.py:346\u001b[39m, in \u001b[36mPDFStream.decode\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    344\u001b[39m     data = lzwdecode(data)\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m LITERALS_ASCII85_DECODE:\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     data = \u001b[43mascii85decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m LITERALS_ASCIIHEX_DECODE:\n\u001b[32m    348\u001b[39m     data = asciihexdecode(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pdfminer\\ascii85.py:27\u001b[39m, in \u001b[36mascii85decode\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m     25\u001b[39m data = start_re.sub(\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, data)\n\u001b[32m     26\u001b[39m data = end_re.sub(\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, data)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43ma85decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\base64.py:410\u001b[39m, in \u001b[36ma85decode\u001b[39m\u001b[34m(b, foldspaces, adobe, ignorechars)\u001b[39m\n\u001b[32m    408\u001b[39m acc = \u001b[32m0\u001b[39m\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m curr:\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     acc = \u001b[32m85\u001b[39m * acc + (x - \u001b[32m33\u001b[39m)\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    412\u001b[39m     decoded_append(packI(acc))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Parsear el PDF completo y construir el JSON desde definiciones SPN\n",
    "import re, json, datetime\n",
    "\n",
    "# Utilidades de parsing\n",
    "\n",
    "def _num(s: str):\n",
    "    s2 = s.strip().replace(\",\", \"\")\n",
    "    try:\n",
    "        return float(s2)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _clean_text(s: str) -> str:\n",
    "    import re as _re\n",
    "    return _re.sub(r\"\\s+\", \" \", s or \"\").strip()\n",
    "\n",
    "\n",
    "def read_pdf_all_text(path: Path) -> str:\n",
    "    try:\n",
    "        import pdfplumber  # type: ignore\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "    if not path.exists():\n",
    "        return \"\"\n",
    "    parts = []\n",
    "    try:\n",
    "        with pdfplumber.open(path) as pdf:\n",
    "            for pg in pdf.pages:\n",
    "                parts.append(pg.extract_text() or \"\")\n",
    "        return \"\\n\\n\".join(parts)\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def parse_spn_blocks(full_text: str):\n",
    "    if not full_text:\n",
    "        return []\n",
    "    block_re = re.compile(\n",
    "        r\"(?is)\\bspn\\s*([0-9]{3,6})\\s*-\\s*(.+?)\\s*-\\s*(.+?)\\s*\"\n",
    "        r\"Data\\s+Length:\\s*([^\\n]+)\\n\"\n",
    "        r\"Resolution:\\s*([^\\n]+)\\n\"\n",
    "        r\"Data\\s+Range:\\s*([^\\n]+)\\n\"\n",
    "        r\"Type:\\s*([^\\n]+)\\n\"\n",
    "        r\"Suspect\\s+Parameter\\s+Number:\\s*([0-9]{3,6})\\n\"\n",
    "        r\"Parameter\\s+Group\\s+Number:\\s*([^\\n]+?)\\s*(?=\\n\\s*spn\\s*[0-9]{3,6}\\s*-|\\Z)\"\n",
    "    )\n",
    "    items = []\n",
    "    for m in block_re.finditer(full_text):\n",
    "        spn_id = int(m.group(1))\n",
    "        name = _clean_text(m.group(2))\n",
    "        desc = _clean_text(m.group(3))\n",
    "        data_len_line = m.group(4).strip()\n",
    "        resolution_line = m.group(5).strip()\n",
    "        range_line = m.group(6).strip()\n",
    "        type_line = m.group(7).strip()\n",
    "        pgn_line = m.group(9).strip()\n",
    "\n",
    "        bits_len = None\n",
    "        mlen = re.search(r\"([0-9.,]+)\\s*(bytes?|bits?)\", data_len_line, re.I)\n",
    "        if mlen:\n",
    "            n = _num(mlen.group(1)) or 0\n",
    "            unit = (mlen.group(2) or \"\").lower()\n",
    "            bits_len = int(round(n * 8)) if \"byte\" in unit else int(round(n))\n",
    "\n",
    "        scale = None\n",
    "        units = None\n",
    "        offset = None\n",
    "        mres = re.search(r\"([\\-0-9.,]+)\\s*([^\\s,]+)?\\s*/\\s*bit.*?([\\-0-9.,]+)\\s*offset\", resolution_line, re.I)\n",
    "        if mres:\n",
    "            scale = _num(mres.group(1))\n",
    "            units = (mres.group(2) or \"\").strip() or None\n",
    "            offset = _num(mres.group(3))\n",
    "\n",
    "        rmin = None\n",
    "        rmax = None\n",
    "        units_range = None\n",
    "        mrange = re.search(r\"([\\-0-9.,]+)\\s*to\\s*([\\-0-9.,]+)\\s*([^\\s%°A-Za-z]*)?\\s*([%°A-Za-z]+)?\", range_line, re.I)\n",
    "        if mrange:\n",
    "            rmin = _num(mrange.group(1))\n",
    "            rmax = _num(mrange.group(2))\n",
    "            units_range = (mrange.group(4) or mrange.group(3) or \"\").strip() or None\n",
    "        if not units and units_range:\n",
    "            units = units_range\n",
    "\n",
    "        if re.search(r\"measured\", type_line, re.I):\n",
    "            spn_type = \"Medido\"\n",
    "        elif re.search(r\"status|state\", type_line, re.I):\n",
    "            spn_type = \"Estado\"\n",
    "        else:\n",
    "            spn_type = _clean_text(type_line)\n",
    "\n",
    "        pgns = [int(x) for x in re.findall(r\"\\[\\s*([0-9]{5})\\s*\\]\", pgn_line)]\n",
    "\n",
    "        items.append({\n",
    "            \"spn\": spn_id,\n",
    "            \"name\": name,\n",
    "            \"description\": desc,\n",
    "            \"units\": units,\n",
    "            \"data_length_bits\": bits_len,\n",
    "            \"resolution\": scale,\n",
    "            \"offset\": offset,\n",
    "            \"range\": {\"min\": rmin, \"max\": rmax} if (rmin is not None or rmax is not None) else None,\n",
    "            \"type\": spn_type,\n",
    "            \"pgns\": pgns,\n",
    "            \"states\": None,\n",
    "            \"notes\": None,\n",
    "        })\n",
    "    return items\n",
    "\n",
    "\n",
    "now_iso = datetime.datetime.utcnow().replace(microsecond=0).isoformat() + 'Z'\n",
    "full_text = read_pdf_all_text(PDF_PATH)\n",
    "spn_items = parse_spn_blocks(full_text)\n",
    "print('SPNs extraídos:', len(spn_items))\n",
    "\n",
    "# Construir PGNs mínimos a partir de asociaciones\n",
    "pgn_map = {}\n",
    "for spn in spn_items:\n",
    "    for pgn in spn.get('pgns', []) or []:\n",
    "        if pgn not in pgn_map:\n",
    "            pgn_map[pgn] = {\n",
    "                'pgn': pgn,\n",
    "                'name': None,\n",
    "                'data_length_bytes': None,\n",
    "                'data_page': None,\n",
    "                'pdu_format': None,\n",
    "                'pdu_specific': None,\n",
    "                'default_priority': None,\n",
    "                'transmission_rate': None,\n",
    "                'signals': [],\n",
    "                'notes': 'Estructura mínima inferida; completar con DBC.'\n",
    "            }\n",
    "        pgn_map[pgn]['signals'].append({\n",
    "            'spn': spn.get('spn'),\n",
    "            'name': spn.get('name'),\n",
    "            'start_bit': None,\n",
    "            'length': spn.get('data_length_bits'),\n",
    "            'endianness': 'Intel',\n",
    "            'units': spn.get('units'),\n",
    "            'scale': spn.get('resolution'),\n",
    "            'offset': spn.get('offset'),\n",
    "            'min': (spn.get('range') or {}).get('min'),\n",
    "            'max': (spn.get('range') or {}).get('max'),\n",
    "            'dbc_link': {'message': None, 'signal': None}\n",
    "        })\n",
    "\n",
    "pgn_list = list(pgn_map.values())\n",
    "\n",
    "# Ensamblar el JSON\n",
    "data = {\n",
    "  'metadata': {\n",
    "    'standard': 'SAE J1939-71',\n",
    "    'description': 'Capa de Aplicación J1939: directrices, definiciones de SPN/PGN y campos para enlazar con DBC. Archivo de referencia para modelos RAG.',\n",
    "    'source_document': 'Entrega4_Precision_Semantica_y_Contextualizacion_Eventos_Vehiculares/J1939-71.pdf',\n",
    "    'created_at': now_iso,\n",
    "    'language': 'es',\n",
    "    'schema_version': '1.0.0'\n",
    "  },\n",
    "  'guidelines': {\n",
    "    'signal_characterization': {\n",
    "      'latency_recommendations': 'Minimizar la latencia entre adquisición y transmisión. Documentar latencia y jitter esperados por parámetro.',\n",
    "      'time_base': 'Algunos PGN dependen del ángulo del cigüeñal/velocidad de motor (sincronizados a fase).'\n",
    "    },\n",
    "    'message_format': {\n",
    "      'pgn': 'El Número de Grupo de Parámetros (PGN) identifica el mensaje y su contenido lógico.',\n",
    "      'data_types': [\n",
    "        'ASCII (ISO/IEC 8859-1 / Latin-1)',\n",
    "        'Datos escalados (factor + offset)',\n",
    "        'Estados de función (bitfields/enumeraciones)'\n",
    "      ],\n",
    "      'byte_order': 'Little-endian (LSB primero) salvo indicación contraria en el SPN/PGN.',\n",
    "      'measured_vs_state': \"Cada SPN se clasifica como 'Medido' o 'Estado'.\"\n",
    "    },\n",
    "    'charset': {\n",
    "      'name': 'ISO/IEC 8859-1 (Latin-1)',\n",
    "      'notes': 'Para campos de texto/ASCII se recomienda Latin-1. Limitar a ASCII imprimible cuando aplique.'\n",
    "    },\n",
    "    'parameter_ranges': {\n",
    "      'general': \"Definir rango válido, valores para 'no disponible' y 'error/indeterminado' según el tipo de dato.\",\n",
    "      'common_conventions': [\n",
    "        \"Para 1 byte: 0..254 suelen mapear a valores/estados válidos, y 255 (0xFF) suele indicar 'no disponible'.\",\n",
    "        \"Para múltiples bytes escalados: usar todo el rango útil, reservando el máximo para 'no disponible' cuando aplique.\",\n",
    "        \"Los valores exactos de 'error'/'no disponible' pueden ser específicos del SPN; ver la definición del SPN.\"\n",
    "      ]\n",
    "    },\n",
    "    'slot_allocation': {\n",
    "      'scaling': 'Definir resolución (factor), offset y límites. Preferir escalas que maximicen el uso del rango sin saturación.',\n",
    "      'limits_and_offsets': 'Explicitar min/max físicos y el offset aplicado.'\n",
    "    },\n",
    "    'adding_parameters_to_groups': {\n",
    "      'grouping': 'Agregar nuevos parámetros a PGNs existentes cuando sea lógico; mantener posiciones y alineación de bytes/bits estables.',\n",
    "      'compatibility': 'Evitar romper compatibilidad hacia atrás; documentar cambios en posiciones/tamaños.'\n",
    "    },\n",
    "    'transmission_rates': {\n",
    "      'nominal_rates': ['10 ms', '20 ms', '100 ms', '1 s', 'a demanda'],\n",
    "      'notes': [\n",
    "        'Elegir tasas periódicas vs. por evento según la dinámica del parámetro.',\n",
    "        'Mensajes dependientes del cigüeñal se envían conforme a la velocidad del motor.'\n",
    "      ]\n",
    "    },\n",
    "    'naming_conventions': {\n",
    "      'multi_component': \"Para parámetros con múltiples instancias, añadir índice/ubicación (ej.: 'temperatura_escape_1', 'temperatura_escape_2').\",\n",
    "      'clarity': 'Mantener nombres consistentes con J1939 para facilitar el cruce con DBC/SPN.'\n",
    "    },\n",
    "    'multi_source_notes': {\n",
    "      'source_priority': 'Si un parámetro tiene múltiples fuentes (ECU diferentes), definir reglas de prioridad y reconciliación.',\n",
    "      'provenance': 'Registrar la ECU origen (Source Address) y la estrategia de selección.'\n",
    "    }\n",
    "  },\n",
    "  'dbc_linkage': {\n",
    "    'can_id_composition': 'ID 29 bits = Prioridad(3) | Reservado(1) | Data Page(1) | PDU Format(8) | PDU Specific(8) | Source Address(8)',\n",
    "    'fields_mapping': {\n",
    "      'dbc_message': {\n",
    "        'name': 'Nombre del mensaje en DBC (habitualmente el nombre del PGN)',\n",
    "        'can_id': 'Identificador CAN extendido de 29 bits',\n",
    "        'pgn': 'Número PGN',\n",
    "        'source_address': '0-255',\n",
    "        'pdu_format': '0-255',\n",
    "        'pdu_specific': '0-255',\n",
    "        'priority': '0-7'\n",
    "      },\n",
    "      'dbc_signal': {\n",
    "        'name': 'Nombre de la señal en DBC (alineado con nombre SPN)',\n",
    "        'spn': 'Número SPN',\n",
    "        'start_bit': 'Bit de inicio (convención Intel/little-endian)',\n",
    "        'length': 'Longitud en bits',\n",
    "        'endianness': 'Intel (little-endian) salvo indicación contraria',\n",
    "        'scale': 'Factor (resolución)',\n",
    "        'offset': 'Offset',\n",
    "        'min': 'Mínimo físico',\n",
    "        'max': 'Máximo físico',\n",
    "        'units': 'Unidades'\n",
    "      }\n",
    "    },\n",
    "    'matching_strategy': [\n",
    "      'Cruzar por SPN (clave primaria semántica).',\n",
    "      'Verificar unidades, resolución y offset.',\n",
    "      'Usar nombre del PGN y señal como respaldo, cuidando sinónimos.',\n",
    "      'Confirmar posiciones (start_bit/length) desde el DBC, no desde este archivo.'\n",
    "    ]\n",
    "  },\n",
    "  'spns': spn_items,\n",
    "  'pgns': pgn_list,\n",
    "  'traceability': {\n",
    "    'sections': {\n",
    "      '5.1': 'Directrices generales (latencia, formato, charset, rangos, slots, agrupación, tasas, nomenclatura, multi-fuente).',\n",
    "      '5.2': 'Definiciones de parámetros (SPN): nombre, descripción, longitud, escala, rango, tipo, SPN, PGN.',\n",
    "      '5.3': 'Definiciones de grupos (PGN): nombre, tasa, longitud, DP/PDU, prioridad, lista de SPNs con posiciones.'\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c10233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesadas 10 páginas; SPNs: 0\n",
      "Procesadas 20 páginas; SPNs: 0\n",
      "Procesadas 30 páginas; SPNs: 0\n",
      "Procesadas 40 páginas; SPNs: 13\n",
      "Procesadas 50 páginas; SPNs: 60\n",
      "Procesadas 60 páginas; SPNs: 84\n",
      "Procesadas 70 páginas; SPNs: 98\n",
      "Procesadas 80 páginas; SPNs: 112\n",
      "Procesadas 20 páginas; SPNs: 0\n",
      "Procesadas 30 páginas; SPNs: 0\n",
      "Procesadas 40 páginas; SPNs: 13\n",
      "Procesadas 50 páginas; SPNs: 60\n",
      "Procesadas 60 páginas; SPNs: 84\n",
      "Procesadas 70 páginas; SPNs: 98\n",
      "Procesadas 80 páginas; SPNs: 112\n",
      "Procesadas 90 páginas; SPNs: 116\n",
      "Procesadas 100 páginas; SPNs: 120\n",
      "Procesadas 110 páginas; SPNs: 136\n",
      "Procesadas 120 páginas; SPNs: 161\n",
      "Procesadas 130 páginas; SPNs: 201\n",
      "Procesadas 140 páginas; SPNs: 237\n",
      "Procesadas 150 páginas; SPNs: 274\n",
      "Procesadas 160 páginas; SPNs: 306\n",
      "Procesadas 170 páginas; SPNs: 351\n",
      "Procesadas 180 páginas; SPNs: 375\n",
      "Procesadas 190 páginas; SPNs: 384\n",
      "Procesadas 200 páginas; SPNs: 402\n",
      "Procesadas 90 páginas; SPNs: 116\n",
      "Procesadas 100 páginas; SPNs: 120\n",
      "Procesadas 110 páginas; SPNs: 136\n",
      "Procesadas 120 páginas; SPNs: 161\n",
      "Procesadas 130 páginas; SPNs: 201\n",
      "Procesadas 140 páginas; SPNs: 237\n",
      "Procesadas 150 páginas; SPNs: 274\n",
      "Procesadas 160 páginas; SPNs: 306\n",
      "Procesadas 170 páginas; SPNs: 351\n",
      "Procesadas 180 páginas; SPNs: 375\n",
      "Procesadas 190 páginas; SPNs: 384\n",
      "Procesadas 200 páginas; SPNs: 402\n",
      "Procesadas 210 páginas; SPNs: 419\n",
      "Procesadas 220 páginas; SPNs: 444\n",
      "Procesadas 230 páginas; SPNs: 455\n",
      "Procesadas 240 páginas; SPNs: 455\n",
      "Procesadas 250 páginas; SPNs: 455\n",
      "Procesadas 260 páginas; SPNs: 474\n",
      "Procesadas 270 páginas; SPNs: 486\n",
      "Procesadas 280 páginas; SPNs: 486\n",
      "Procesadas 290 páginas; SPNs: 494\n",
      "Procesadas 300 páginas; SPNs: 494\n",
      "Procesadas 310 páginas; SPNs: 494\n",
      "Procesadas 210 páginas; SPNs: 419\n",
      "Procesadas 220 páginas; SPNs: 444\n",
      "Procesadas 230 páginas; SPNs: 455\n",
      "Procesadas 240 páginas; SPNs: 455\n",
      "Procesadas 250 páginas; SPNs: 455\n",
      "Procesadas 260 páginas; SPNs: 474\n",
      "Procesadas 270 páginas; SPNs: 486\n",
      "Procesadas 280 páginas; SPNs: 486\n",
      "Procesadas 290 páginas; SPNs: 494\n",
      "Procesadas 300 páginas; SPNs: 494\n",
      "Procesadas 310 páginas; SPNs: 494\n",
      "Procesadas 320 páginas; SPNs: 494\n",
      "Procesadas 330 páginas; SPNs: 494\n",
      "Procesadas 340 páginas; SPNs: 494\n",
      "Procesadas 350 páginas; SPNs: 494\n",
      "Procesadas 360 páginas; SPNs: 494\n",
      "Procesadas 370 páginas; SPNs: 494\n",
      "Total SPNs extraídos (stream): 494\n",
      "Procesadas 320 páginas; SPNs: 494\n",
      "Procesadas 330 páginas; SPNs: 494\n",
      "Procesadas 340 páginas; SPNs: 494\n",
      "Procesadas 350 páginas; SPNs: 494\n",
      "Procesadas 360 páginas; SPNs: 494\n",
      "Procesadas 370 páginas; SPNs: 494\n",
      "Total SPNs extraídos (stream): 494\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 198\u001b[39m\n\u001b[32m    181\u001b[39m         pgn_map[pgn][\u001b[33m'\u001b[39m\u001b[33msignals\u001b[39m\u001b[33m'\u001b[39m].append({\n\u001b[32m    182\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mspn\u001b[39m\u001b[33m'\u001b[39m: spn.get(\u001b[33m'\u001b[39m\u001b[33mspn\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m    183\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m: spn.get(\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m    192\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mdbc_link\u001b[39m\u001b[33m'\u001b[39m: {\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33msignal\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[32m    193\u001b[39m         })\n\u001b[32m    195\u001b[39m pgn_list = \u001b[38;5;28mlist\u001b[39m(pgn_map.values())\n\u001b[32m    197\u001b[39m data = {\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m   \u001b[33m'\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mdata\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    199\u001b[39m   \u001b[33m'\u001b[39m\u001b[33mguidelines\u001b[39m\u001b[33m'\u001b[39m: data[\u001b[33m'\u001b[39m\u001b[33mguidelines\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    200\u001b[39m   \u001b[33m'\u001b[39m\u001b[33mdbc_linkage\u001b[39m\u001b[33m'\u001b[39m: data[\u001b[33m'\u001b[39m\u001b[33mdbc_linkage\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    201\u001b[39m   \u001b[33m'\u001b[39m\u001b[33mspns\u001b[39m\u001b[33m'\u001b[39m: spn_items_stream,\n\u001b[32m    202\u001b[39m   \u001b[33m'\u001b[39m\u001b[33mpgns\u001b[39m\u001b[33m'\u001b[39m: pgn_list,\n\u001b[32m    203\u001b[39m   \u001b[33m'\u001b[39m\u001b[33mtraceability\u001b[39m\u001b[33m'\u001b[39m: data[\u001b[33m'\u001b[39m\u001b[33mtraceability\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    204\u001b[39m }\n",
      "\u001b[31mNameError\u001b[39m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# Parser streaming rápido con PyMuPDF (fitz) independiente (no depende de 'data' previa)\n",
    "# - Procesa el PDF por chunks y muestra progreso\n",
    "# - Limita páginas con MAX_PAGES para pruebas rápidas (None para procesar todo)\n",
    "\n",
    "import importlib, sys, subprocess, re, datetime\n",
    "from pathlib import Path as _PathAlias  # para evitar conflictos de nombres\n",
    "\n",
    "# Parámetros de rendimiento\n",
    "MAX_PAGES = 50  # ponlo en None para procesar todo el PDF\n",
    "CHUNK_PAGES = 10\n",
    "ENGINE = 'fitz'  # 'fitz' (PyMuPDF) o 'pdfplumber'\n",
    "\n",
    "# Asegurar PyMuPDF si se va a usar\n",
    "if ENGINE == 'fitz':\n",
    "    try:\n",
    "        import fitz  # PyMuPDF\n",
    "    except Exception:\n",
    "        print('Instalando PyMuPDF…')\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pymupdf'])\n",
    "        import fitz\n",
    "\n",
    "# Fallback a pdfplumber para lectura por página si fitz no está disponible\n",
    "try:\n",
    "    import pdfplumber as _pp\n",
    "except Exception:\n",
    "    print('Instalando pdfplumber…')\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pdfplumber'])\n",
    "    import pdfplumber as _pp\n",
    "\n",
    "\n",
    "def iter_pages_text_nb(pdf_path: _PathAlias, engine: str = 'fitz'):\n",
    "    if engine == 'fitz':\n",
    "        try:\n",
    "            with fitz.open(pdf_path) as doc:\n",
    "                for page in doc:\n",
    "                    yield page.get_text('text') or ''\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print('Aviso: PyMuPDF falló; usando pdfplumber…', e)\n",
    "    with _pp.open(pdf_path) as pdf:\n",
    "        for p in pdf.pages:\n",
    "            yield p.extract_text() or ''\n",
    "\n",
    "\n",
    "pattern = re.compile(\n",
    "    r\"(?is)\\bspn\\s*([0-9]{3,6})\\s*-\\s*(.+?)\\s*-\\s*(.+?)\\s*\"\n",
    "    r\"Data\\s+Length:\\s*([^\\n]+)\\n\"\n",
    "    r\"Resolution:\\s*([^\\n]+)\\n\"\n",
    "    r\"Data\\s+Range:\\s*([^\\n]+)\\n\"\n",
    "    r\"Type:\\s*([^\\n]+)\\n\"\n",
    "    r\"Suspect\\s+Parameter\\s+Number:\\s*([0-9]{3,6})\\n\"\n",
    "    r\"Parameter\\s+Group\\s+Number:\\s*([^\\n]+?)\\s*(?=\\n\\s*spn\\s*[0-9]{3,6}\\s*-|\\Z)\"\n",
    ")\n",
    "\n",
    "\n",
    "def _num(s: str):\n",
    "    try:\n",
    "        return float(s.strip().replace(',', ''))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Streaming parse con progreso y límite de páginas\n",
    "spn_items_stream = []\n",
    "buf = []\n",
    "lead = ''\n",
    "page_count = 0\n",
    "for text in iter_pages_text_nb(PDF_PATH, engine=ENGINE):\n",
    "    page_count += 1\n",
    "    buf.append(text)\n",
    "    if len(buf) >= CHUNK_PAGES:\n",
    "        chunk = lead + \"\\n\\n\".join(buf)\n",
    "        lead = chunk[-2000:]\n",
    "        for m in pattern.finditer(chunk):\n",
    "            spn_id = int(m.group(1))\n",
    "            name = _clean_text(m.group(2))\n",
    "            desc = _clean_text(m.group(3))\n",
    "            data_len_line = m.group(4).strip()\n",
    "            resolution_line = m.group(5).strip()\n",
    "            range_line = m.group(6).strip()\n",
    "            type_line = m.group(7).strip()\n",
    "            pgn_line = m.group(9).strip()\n",
    "            # Data Length\n",
    "            bits_len = None\n",
    "            mlen = re.search(r\"([0-9.,]+)\\s*(bytes?|bits?)\", data_len_line, re.I)\n",
    "            if mlen:\n",
    "                n = _num(mlen.group(1)) or 0\n",
    "                unit = (mlen.group(2) or '').lower()\n",
    "                bits_len = int(round(n*8)) if 'byte' in unit else int(round(n))\n",
    "            # Resolution\n",
    "            scale = None; units = None; offset = None\n",
    "            mres = re.search(r\"([\\-0-9.,]+)\\s*([^\\s,]+)?\\s*/\\s*bit.*?([\\-0-9.,]+)\\s*offset\", resolution_line, re.I)\n",
    "            if mres:\n",
    "                scale = _num(mres.group(1))\n",
    "                units = (mres.group(2) or '').strip() or None\n",
    "                offset = _num(mres.group(3))\n",
    "            # Range\n",
    "            rmin = None; rmax = None; units_range = None\n",
    "            mrange = re.search(r\"([\\-0-9.,]+)\\s*to\\s*([\\-0-9.,]+)\\s*([^\\s%°A-Za-z]*)?\\s*([%°A-Za-z]+)?\", range_line, re.I)\n",
    "            if mrange:\n",
    "                rmin = _num(mrange.group(1)); rmax = _num(mrange.group(2))\n",
    "                units_range = (mrange.group(4) or mrange.group(3) or '').strip() or None\n",
    "            if not units and units_range:\n",
    "                units = units_range\n",
    "            # Type\n",
    "            if re.search(r'measured', type_line, re.I):\n",
    "                spn_type = 'Medido'\n",
    "            elif re.search(r'status|state', type_line, re.I):\n",
    "                spn_type = 'Estado'\n",
    "            else:\n",
    "                spn_type = _clean_text(type_line)\n",
    "            # PGNs\n",
    "            pgns = [int(x) for x in re.findall(r\"\\[\\s*([0-9]{5})\\s*\\]\", pgn_line)]\n",
    "            spn_items_stream.append({\n",
    "                'spn': spn_id,\n",
    "                'name': name,\n",
    "                'description': desc,\n",
    "                'units': units,\n",
    "                'data_length_bits': bits_len,\n",
    "                'resolution': scale,\n",
    "                'offset': offset,\n",
    "                'range': {'min': rmin, 'max': rmax} if (rmin is not None or rmax is not None) else None,\n",
    "                'type': spn_type,\n",
    "                'pgns': pgns,\n",
    "                'states': None,\n",
    "                'notes': None,\n",
    "            })\n",
    "        print(f\"Procesadas {page_count} páginas; SPNs: {len(spn_items_stream)}\")\n",
    "        buf = []\n",
    "    if MAX_PAGES is not None and page_count >= MAX_PAGES:\n",
    "        print(f\"Límite MAX_PAGES alcanzado: {MAX_PAGES}\")\n",
    "        break\n",
    "\n",
    "# Procesar resto del buffer\n",
    "if buf:\n",
    "    chunk = lead + \"\\n\\n\".join(buf)\n",
    "    for m in pattern.finditer(chunk):\n",
    "        spn_id = int(m.group(1))\n",
    "        name = _clean_text(m.group(2))\n",
    "        desc = _clean_text(m.group(3))\n",
    "        data_len_line = m.group(4).strip()\n",
    "        resolution_line = m.group(5).strip()\n",
    "        range_line = m.group(6).strip()\n",
    "        type_line = m.group(7).strip()\n",
    "        pgn_line = m.group(9).strip()\n",
    "        bits_len = None\n",
    "        mlen = re.search(r\"([0-9.,]+)\\s*(bytes?|bits?)\", data_len_line, re.I)\n",
    "        if mlen:\n",
    "            n = _num(mlen.group(1)) or 0\n",
    "            unit = (mlen.group(2) or '').lower()\n",
    "            bits_len = int(round(n*8)) if 'byte' in unit else int(round(n))\n",
    "        scale = None; units = None; offset = None\n",
    "        mres = re.search(r\"([\\-0-9.,]+)\\s*([^\\s,]+)?\\s*/\\s*bit.*?([\\-0-9.,]+)\\s*offset\", resolution_line, re.I)\n",
    "        if mres:\n",
    "            scale = _num(mres.group(1)); units = (mres.group(2) or '').strip() or None; offset = _num(mres.group(3))\n",
    "        rmin = None; rmax = None; units_range = None\n",
    "        mrange = re.search(r\"([\\-0-9.,]+)\\s*to\\s*([\\-0-9.,]+)\\s*([^\\s%°A-Za-z]*)?\\s*([%°A-Za-z]+)?\", range_line, re.I)\n",
    "        if mrange:\n",
    "            rmin = _num(mrange.group(1)); rmax = _num(mrange.group(2)); units_range = (mrange.group(4) or mrange.group(3) or '').strip() or None\n",
    "        if not units and units_range:\n",
    "            units = units_range\n",
    "        if re.search(r'measured', type_line, re.I):\n",
    "            spn_type = 'Medido'\n",
    "        elif re.search(r'status|state', type_line, re.I):\n",
    "            spn_type = 'Estado'\n",
    "        else:\n",
    "            spn_type = _clean_text(type_line)\n",
    "        pgns = [int(x) for x in re.findall(r\"\\[\\s*([0-9]{5})\\s*\\]\", pgn_line)]\n",
    "        spn_items_stream.append({\n",
    "            'spn': spn_id,\n",
    "            'name': name,\n",
    "            'description': desc,\n",
    "            'units': units,\n",
    "            'data_length_bits': bits_len,\n",
    "            'resolution': scale,\n",
    "            'offset': offset,\n",
    "            'range': {'min': rmin, 'max': rmax} if (rmin is not None or rmax is not None) else None,\n",
    "            'type': spn_type,\n",
    "            'pgns': pgns,\n",
    "            'states': None,\n",
    "            'notes': None,\n",
    "        })\n",
    "\n",
    "print(f\"Total SPNs extraídos (stream): {len(spn_items_stream)}\")\n",
    "\n",
    "# Reconstruir pgn_list a partir de asociaciones SPN->PGN (sin start_bit; se completa con DBC)\n",
    "pgn_map = {}\n",
    "for spn in spn_items_stream:\n",
    "    for pgn in spn.get('pgns', []) or []:\n",
    "        if pgn not in pgn_map:\n",
    "            pgn_map[pgn] = {\n",
    "                'pgn': pgn,\n",
    "                'name': None,\n",
    "                'data_length_bytes': None,\n",
    "                'data_page': None,\n",
    "                'pdu_format': None,\n",
    "                'pdu_specific': None,\n",
    "                'default_priority': None,\n",
    "                'transmission_rate': None,\n",
    "                'signals': [],\n",
    "                'notes': 'Estructura mínima inferida; completar con DBC.'\n",
    "            }\n",
    "        pgn_map[pgn]['signals'].append({\n",
    "            'spn': spn.get('spn'),\n",
    "            'name': spn.get('name'),\n",
    "            'start_bit': None,\n",
    "            'length': spn.get('data_length_bits'),\n",
    "            'endianness': 'Intel',\n",
    "            'units': spn.get('units'),\n",
    "            'scale': spn.get('resolution'),\n",
    "            'offset': spn.get('offset'),\n",
    "            'min': (spn.get('range') or {}).get('min'),\n",
    "            'max': (spn.get('range') or {}).get('max'),\n",
    "            'dbc_link': {'message': None, 'signal': None}\n",
    "        })\n",
    "\n",
    "pgn_list = list(pgn_map.values())\n",
    "\n",
    "# Construir data completo e independiente\n",
    "now_iso = datetime.datetime.utcnow().replace(microsecond=0).isoformat() + 'Z'\n",
    "metadata_block = {\n",
    "  'standard': 'SAE J1939-71',\n",
    "  'description': 'Capa de Aplicación J1939: directrices, definiciones de SPN/PGN y campos para enlazar con DBC. Archivo de referencia para modelos RAG.',\n",
    "  'source_document': 'Entrega4_Precision_Semantica_y_Contextualizacion_Eventos_Vehiculares/J1939-71.pdf',\n",
    "  'created_at': now_iso,\n",
    "  'language': 'es',\n",
    "  'schema_version': '1.0.0'\n",
    "}\n",
    "\n",
    "guidelines_block = {\n",
    "  'signal_characterization': {\n",
    "    'latency_recommendations': 'Minimizar la latencia entre adquisición y transmisión. Documentar latencia y jitter esperados por parámetro.',\n",
    "    'time_base': 'Algunos PGN dependen del ángulo del cigüeñal/velocidad de motor (sincronizados a fase).'\n",
    "  },\n",
    "  'message_format': {\n",
    "    'pgn': 'El Número de Grupo de Parámetros (PGN) identifica el mensaje y su contenido lógico.',\n",
    "    'data_types': [\n",
    "      'ASCII (ISO/IEC 8859-1 / Latin-1)',\n",
    "      'Datos escalados (factor + offset)',\n",
    "      'Estados de función (bitfields/enumeraciones)'\n",
    "    ],\n",
    "    'byte_order': 'Little-endian (LSB primero) salvo indicación contraria en el SPN/PGN.',\n",
    "    'measured_vs_state': \"Cada SPN se clasifica como 'Medido' o 'Estado'.\"\n",
    "  },\n",
    "  'charset': {\n",
    "    'name': 'ISO/IEC 8859-1 (Latin-1)',\n",
    "    'notes': 'Para campos de texto/ASCII se recomienda Latin-1. Limitar a ASCII imprimible cuando aplique.'\n",
    "  },\n",
    "  'parameter_ranges': {\n",
    "    'general': \"Definir rango válido, valores para 'no disponible' y 'error/indeterminado' según el tipo de dato.\",\n",
    "    'common_conventions': [\n",
    "      \"Para 1 byte: 0..254 suelen mapear a valores/estados válidos, y 255 (0xFF) suele indicar 'no disponible'.\",\n",
    "      \"Para múltiples bytes escalados: usar todo el rango útil, reservando el máximo para 'no disponible' cuando aplique.\",\n",
    "      \"Los valores exactos de 'error'/'no disponible' pueden ser específicos del SPN; ver la definición del SPN.\"\n",
    "    ]\n",
    "  },\n",
    "  'slot_allocation': {\n",
    "    'scaling': 'Definir resolución (factor), offset y límites. Preferir escalas que maximicen el uso del rango sin saturación.',\n",
    "    'limits_and_offsets': 'Explicitar min/max físicos y el offset aplicado.'\n",
    "  },\n",
    "  'adding_parameters_to_groups': {\n",
    "    'grouping': 'Agregar nuevos parámetros a PGNs existentes cuando sea lógico; mantener posiciones y alineación de bytes/bits estables.',\n",
    "    'compatibility': 'Evitar romper compatibilidad hacia atrás; documentar cambios en posiciones/tamaños.'\n",
    "  },\n",
    "  'transmission_rates': {\n",
    "    'nominal_rates': ['10 ms', '20 ms', '100 ms', '1 s', 'a demanda'],\n",
    "    'notes': [\n",
    "      'Elegir tasas periódicas vs. por evento según la dinámica del parámetro.',\n",
    "      'Mensajes dependientes del cigüeñal se envían conforme a la velocidad del motor.'\n",
    "    ]\n",
    "  },\n",
    "  'naming_conventions': {\n",
    "    'multi_component': \"Para parámetros con múltiples instancias, añadir índice/ubicación (ej.: 'temperatura_escape_1', 'temperatura_escape_2').\",\n",
    "    'clarity': 'Mantener nombres consistentes con J1939 para facilitar el cruce con DBC/SPN.'\n",
    "  },\n",
    "  'multi_source_notes': {\n",
    "    'source_priority': 'Si un parámetro tiene múltiples fuentes (ECU diferentes), definir reglas de prioridad y reconciliación.',\n",
    "    'provenance': 'Registrar la ECU origen (Source Address) y la estrategia de selección.'\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "dbc_linkage_block = {\n",
    "  'can_id_composition': 'ID 29 bits = Prioridad(3) | Reservado(1) | Data Page(1) | PDU Format(8) | PDU Specific(8) | Source Address(8)',\n",
    "  'fields_mapping': {\n",
    "    'dbc_message': {\n",
    "      'name': 'Nombre del mensaje en DBC (habitualmente el nombre del PGN)',\n",
    "      'can_id': 'Identificador CAN extendido de 29 bits',\n",
    "      'pgn': 'Número PGN',\n",
    "      'source_address': '0-255',\n",
    "      'pdu_format': '0-255',\n",
    "      'pdu_specific': '0-255',\n",
    "      'priority': '0-7'\n",
    "    },\n",
    "    'dbc_signal': {\n",
    "      'name': 'Nombre de la señal en DBC (alineado con nombre SPN)',\n",
    "      'spn': 'Número SPN',\n",
    "      'start_bit': 'Bit de inicio (convención Intel/little-endian)',\n",
    "      'length': 'Longitud en bits',\n",
    "      'endianness': 'Intel (little-endian) salvo indicación contraria',\n",
    "      'scale': 'Factor (resolución)',\n",
    "      'offset': 'Offset',\n",
    "      'min': 'Mínimo físico',\n",
    "      'max': 'Máximo físico',\n",
    "      'units': 'Unidades'\n",
    "    }\n",
    "  },\n",
    "  'matching_strategy': [\n",
    "    'Cruzar por SPN (clave primaria semántica).',\n",
    "    'Verificar unidades, resolución y offset.',\n",
    "    'Usar nombre del PGN y señal como respaldo, cuidando sinónimos.',\n",
    "    'Confirmar posiciones (start_bit/length) desde el DBC, no desde este archivo.'\n",
    "  ]\n",
    "}\n",
    "\n",
    "traceability_block = {\n",
    "  'sections': {\n",
    "    '5.1': 'Directrices generales (latencia, formato, charset, rangos, slots, agrupación, tasas, nomenclatura, multi-fuente).',\n",
    "    '5.2': 'Definiciones de parámetros (SPN): nombre, descripción, longitud, escala, rango, tipo, SPN, PGN.',\n",
    "    '5.3': 'Definiciones de grupos (PGN): nombre, tasa, longitud, DP/PDU, prioridad, lista de SPNs con posiciones.'\n",
    "  }\n",
    "}\n",
    "\n",
    "# Ensamblar data final\n",
    "data = {\n",
    "  'metadata': metadata_block,\n",
    "  'guidelines': guidelines_block,\n",
    "  'dbc_linkage': dbc_linkage_block,\n",
    "  'spns': spn_items_stream,\n",
    "  'pgns': pgn_list,\n",
    "  'traceability': traceability_block\n",
    "}\n",
    "\n",
    "print('data listo con:', len(data.get('spns', [])), 'SPNs y', len(data.get('pgns', [])), 'PGNs inferidos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dbd030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el JSON en disco\n",
    "OUTPUT_JSON.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "print('JSON escrito en:', OUTPUT_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d171c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de verificación\n",
    "with open(OUTPUT_JSON, 'r', encoding='utf-8') as f:\n",
    "    loaded = json.load(f)\n",
    "print('Claves de nivel superior:', list(loaded.keys()))\n",
    "print('SPNs de ejemplo:', [s['spn'] for s in loaded.get('spns', [])])\n",
    "print('PGNs de ejemplo:', [p['pgn'] for p in loaded.get('pgns', [])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
