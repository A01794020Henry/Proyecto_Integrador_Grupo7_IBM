{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46904d94",
   "metadata": {},
   "source": [
    "![Tecnológico de Monterrey Logo](https://javier.rodriguez.org.mx/itesm/2014/tecnologico-de-monterrey-blue.png)\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "\n",
    "# Maestría en Inteligencia Artificial Aplicada\n",
    "\n",
    "## Proyecto Integrador - IBM\n",
    "\n",
    "**Profesor Titular:** Carlos Alberto Villaseñor  \n",
    "\n",
    "**Tema:** Ingenieria de Requerimientos (TC5035) \n",
    "\n",
    "**Entregable**: Entrega 2 - Proyecto Integrador\n",
    "\n",
    "**Semana:** Semana Tres\n",
    "\n",
    "**Estudiantes:**\n",
    "\n",
    "| Nombre                  | Matrícula    |\n",
    "|-------------------------|--------------|\n",
    "| Henry Junior Aranzales Lopez    | A01794020   |\n",
    "| Jorge Arturo Hernandez Morales   | A01794908   |\n",
    "| Luis Alejandro Gonzales Castellanos      | A01795481    |\n",
    "\n",
    "**Grupo:** Grupo 07 \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b24437",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En el presente notebook se describe la implementación integral de **transformacón de datos vehiculares CAN** hacia representaciones semánticas compatibles con arquitecturas **Large Language Model (LLM)** y sistemas **Retrieval-Augmented Generation (RAG)**; permitiendo la migración desde técnicas tradicionales de ingeniería de características hacia metodologías de enriquecimiento semantico y contextualización de dominio. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627f42aa",
   "metadata": {},
   "source": [
    "## Objetivos Estratégicos del Sistema\n",
    "\n",
    "**Objetivo Principal:** Desarrollar un pipeline de transformación semántica que convierta señales numéricas del protocolo CAN (Controller Area Network) en representaciones textuales enriquecidas, facilitando la interpretación de eventos vehiculares mediante interfaces conversacionales basadas en procesamiento de lenguaje natural.\n",
    "\n",
    "**Objetivos Específicos:**\n",
    "1. **Transformación Semántica:** Generar descripciones textuales técnicamente precisas de señales CAN mediante técnicas de generación controlada\n",
    "2. **Enriquecimiento Contextual:** Crear metadatos estructurados que preserven información técnica crítica para sistemas RAG\n",
    "3. **Construcción de Base de Conocimiento:** Desarrollar un prototipo funcional de corpus documental especializado en el dominio vehicular eléctrico\n",
    "4. **Optimización RAG:** Generar dataset compatible con arquitecturas de recuperación-generación para consultas técnicas especializadas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624ac881",
   "metadata": {},
   "source": [
    "## Alcance \n",
    "\n",
    "### Innovación Metodológica: Cambio de Paradigma\n",
    "\n",
    "La metodología implementada busca construir las bases del contexto para lograr la siguiente transición: \n",
    "\n",
    "**Paradigma Tradicional (ML Clásico):**\n",
    "- Extracción de características numéricas estadísticas\n",
    "- Transformaciones matemáticas para optimización algorítmica\n",
    "- Enfoque en precisión predictiva cuantitativa\n",
    "\n",
    "**Paradigma Propuesto (LLM/RAG):**\n",
    "- Generación de representaciones semánticas contextualizadas\n",
    "- Preservación de conocimiento técnico dominio-específico\n",
    "- Enfoque en interpretabilidad y accesibilidad conversacional\n",
    "\n",
    "### Contexto de Datos y Complejidad del Dominio\n",
    "\n",
    "**Base de Datos CAN Analizada:**\n",
    "\n",
    "El sistema vehicular del prototipo de la empresa Superpolo SAS se compone de cuatro canales CAN, en esta etapa, el foco de trabajo se centra en los canales:\n",
    "\n",
    "- **CAN_EV:** 1,957 señales vehiculares (30% con documentación técnica disponible)\n",
    "- **CAN_CATL:** 162 señales del sistema de batería (0% documentación - \"caja negra\" propietaria)\n",
    "\n",
    "Los siguentes canales aun no se procesan: \n",
    "- **CAN_CARROC:** Sistema de control de carrocería y puertas\n",
    "- **AUX_CHG:** Subsistema de carga y gestión energética\n",
    "\n",
    "**Nota: La data disponible para el procesamiento y obtención de datos se trabajará de manera local en los equipos de los miembros del grupo de trabajo.**\n",
    "\n",
    "\n",
    "**Desafíos Técnicos Identificados:**\n",
    "1. **Heterogeneidad semántica** entre subsistemas vehiculares\n",
    "2. **Ausencia de documentación** en componentes propietarios\n",
    "3. **Variabilidad temporal** en patrones de señales CAN\n",
    "4. **Complejidad de interpretación** para usuarios no técnicos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a613403",
   "metadata": {},
   "source": [
    "## Metodología de Desarrollo: Marco Teórico CRISP-ML Adaptado\n",
    "\n",
    "### Fundamentación Metodológica\n",
    "\n",
    "La metodología empleada se fundamenta en una adaptación especializada del marco **CRISP-ML (Cross Industry Standard Process for Machine Learning)**, específicamente reinterpretado para sistemas basados en **Large Language Models** y arquitecturas **RAG**. Esta adaptación reconoce las diferencias fundamentales entre el desarrollo de sistemas ML tradicionales y la construcción de sistemas de inteligencia artificial conversacional.\n",
    "\n",
    "### Posicionamiento en el Ciclo de Vida ML\n",
    "\n",
    "El presente desarrollo se ubica estratégicamente en la fase de **\"Preparación y Transformación de Datos\"** del ciclo CRISP-ML, pero incorporando consideraciones específicas para sistemas LLM:\n",
    "\n",
    "#### Fase 1: Generación de Descripciones Textuales Semánticas\n",
    "**Fundamentación Teórica:** La transformación de señales numéricas CAN en representaciones textuales requiere la aplicación de técnicas de **generación controlada** que preserven la precisión técnica mientras mejoren la interpretabilidad humana.\n",
    "\n",
    "**Metodología Específica:**\n",
    "- Aplicación de plantillas semánticas dominio-específicas\n",
    "- Preservación de unidades de medida y rangos operacionales\n",
    "- Contextualización temporal y situacional de eventos\n",
    "\n",
    "#### Fase 2: Construcción de Metadatos Estructurados\n",
    "**Fundamentación Teórica:** Los sistemas RAG requieren metadatos enriquecidos que faciliten la recuperación semántica precisa y la generación contextualmente relevante.\n",
    "\n",
    "**Implementación Técnica:**\n",
    "- Esquemas JSON estructurados con validación semántica\n",
    "- Taxonomías jerárquicas de componentes vehiculares\n",
    "- Mappings de relaciones entre subsistemas CAN\n",
    "\n",
    "#### Fase 3: Preparación de Corpus Documental Especializado\n",
    "**Fundamentación Teórica:** La efectividad de sistemas RAG depende críticamente de la calidad y especialización del corpus documental utilizado para recuperación contextual.\n",
    "\n",
    "**Estrategia de Construcción:**\n",
    "- Integración de estándares técnicos J1939 y SAE\n",
    "- Documentación de mejores prácticas industriales\n",
    "- Generación sintética de ejemplos edge-case\n",
    "\n",
    "#### Fase 4: Optimización de Dataset para Arquitecturas RAG\n",
    "**Fundamentación Teórica:** La construcción de datasets RAG requiere consideraciones específicas de chunking, embeddings y recuperación semántica que difieren significativamente de datasets ML tradicionales.\n",
    "\n",
    "## Entregables Técnicos Especificados\n",
    "\n",
    "#### 1. Pipeline de Transformación Semántica\n",
    "**Descripción:** Sistema modular de clases Python que implementa transformaciones CAN→Texto con validación de calidad automática.\n",
    "\n",
    "**Componentes Técnicos:**\n",
    "- `GeneradorDescripcionesTextual`: Motor de transformación semántica\n",
    "- `ValidadorCalidadSemántica`: Sistema de métricas de calidad\n",
    "- `OptimizadorContextual`: Módulo de enriquecimiento contextual\n",
    "\n",
    "## Contribuciones Técnicas Esperadas\n",
    "\n",
    "1. **Innovación Metodológica:** Primera implementación documentada de pipeline CAN→RAG en contexto vehicular colombiano\n",
    "2. **Validación Empírica:** Métricas cuantitativas de calidad semántica y efectividad de recuperación\n",
    "3. **Replicabilidad:** Framework modular reutilizable para otros dominios vehiculares\n",
    "4. **Escalabilidad:** Arquitectura preparada para integración con sistemas Watson IBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4066afb",
   "metadata": {},
   "source": [
    "## 1. Configuración Técnica del Entorno de Desarrollo\n",
    "\n",
    "Para la configuración del entorno de desarrolo se han seleccionado y usado las siguientes dependencias: \n",
    "\n",
    "**Categoría 1: Procesamiento de Datos Vehiculares**\n",
    "- `pandas/numpy`: Manipulación eficiente de datasets CAN de gran volumen\n",
    "- `matplotlib/seaborn/plotly`: Visualización de patrones temporales en señales\n",
    "\n",
    "**Categoría 2: Capacidades LLM/RAG**\n",
    "- `langchain`: Framework de orquestación para sistemas RAG\n",
    "- `sentence-transformers`: Generación de embeddings semánticos\n",
    "- `tiktoken`: Tokenización compatible con modelos GPT\n",
    "\n",
    "**Categoría 3: Formato y Persistencia**\n",
    "- `jsonlines`: Manejo eficiente de datasets RAG en formato JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "001a201e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado: Iniciando configuración del entorno DECODE-EV...\n",
      "============================================================\n",
      "pandas>=1.5.0 instalado correctamente\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.5.0) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.5.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.5.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.5.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0) (1.17.0)\n",
      "\n",
      "pandas>=1.5.0 instalado correctamente\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.5.0) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.5.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.5.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.5.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0) (1.17.0)\n",
      "\n",
      "numpy>=1.21.0 instalado correctamente\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "\n",
      "numpy>=1.21.0 instalado correctamente\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "\n",
      "matplotlib>=3.5.0 instalado correctamente\n",
      "Requirement already satisfied: matplotlib>=3.5.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.5.0) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.5.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.5.0) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.5.0) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.5.0) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.5.0) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.5.0) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.5.0) (3.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.5.0) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.5.0) (1.17.0)\n",
      "\n",
      "matplotlib>=3.5.0 instalado correctamente\n",
      "Requirement already satisfied: matplotlib>=3.5.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.5.0) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.5.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.5.0) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.5.0) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.5.0) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.5.0) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.5.0) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.5.0) (3.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.5.0) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.5.0) (1.17.0)\n",
      "\n",
      "seaborn>=0.11.0 instalado correctamente\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn>=0.11.0) (2.3.3)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn>=0.11.0) (2.3.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn>=0.11.0) (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (3.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2->seaborn>=0.11.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2->seaborn>=0.11.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (1.17.0)\n",
      "\n",
      "seaborn>=0.11.0 instalado correctamente\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn>=0.11.0) (2.3.3)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn>=0.11.0) (2.3.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn>=0.11.0) (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (3.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2->seaborn>=0.11.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2->seaborn>=0.11.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (1.17.0)\n",
      "\n",
      "langchain>=0.1.0 instalado correctamente\n",
      "Requirement already satisfied: langchain>=0.1.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain>=0.1.0) (0.3.78)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain>=0.1.0) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain>=0.1.0) (0.4.32)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain>=0.1.0) (2.11.10)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain>=0.1.0) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain>=0.1.0) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain>=0.1.0) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain>=0.1.0) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain>=0.1.0) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain>=0.1.0) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain>=0.1.0) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain>=0.1.0) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain>=0.1.0) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain>=0.1.0) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain>=0.1.0) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain>=0.1.0) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain>=0.1.0) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain>=0.1.0) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain>=0.1.0) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain>=0.1.0) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain>=0.1.0) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.1.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.1.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.1.0) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2->langchain>=0.1.0) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2->langchain>=0.1.0) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.1.0) (3.2.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain>=0.1.0) (1.3.1)\n",
      "\n",
      "langchain>=0.1.0 instalado correctamente\n",
      "Requirement already satisfied: langchain>=0.1.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain>=0.1.0) (0.3.78)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain>=0.1.0) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain>=0.1.0) (0.4.32)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain>=0.1.0) (2.11.10)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain>=0.1.0) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain>=0.1.0) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain>=0.1.0) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain>=0.1.0) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain>=0.1.0) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain>=0.1.0) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain>=0.1.0) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain>=0.1.0) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain>=0.1.0) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain>=0.1.0) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain>=0.1.0) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith>=0.1.17->langchain>=0.1.0) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain>=0.1.0) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain>=0.1.0) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain>=0.1.0) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain>=0.1.0) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain>=0.1.0) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.1.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.1.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.1.0) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2->langchain>=0.1.0) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2->langchain>=0.1.0) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.1.0) (3.2.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain>=0.1.0) (1.3.1)\n",
      "\n",
      "langchain-community instalado correctamente\n",
      "Requirement already satisfied: langchain-community in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.30)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (0.3.78)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (2.0.43)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (2.11.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (0.4.32)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (2.3.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.21.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.10)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.75->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "\n",
      "langchain-community instalado correctamente\n",
      "Requirement already satisfied: langchain-community in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.30)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (0.3.78)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (2.0.43)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (2.11.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (0.4.32)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (2.3.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.21.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.10)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.75->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "\n",
      "sentence-transformers instalado correctamente\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.1.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.57.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (1.16.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\haranzales\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.8.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "\n",
      "sentence-transformers instalado correctamente\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.1.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.57.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (1.16.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\haranzales\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.8.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "\n",
      "tiktoken instalado correctamente\n",
      "Requirement already satisfied: tiktoken in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tiktoken) (2025.9.18)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n",
      "\n",
      "tiktoken instalado correctamente\n",
      "Requirement already satisfied: tiktoken in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tiktoken) (2025.9.18)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n",
      "\n",
      "jsonlines instalado correctamente\n",
      "Requirement already satisfied: jsonlines in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonlines) (25.3.0)\n",
      "\n",
      "jsonlines instalado correctamente\n",
      "Requirement already satisfied: jsonlines in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonlines) (25.3.0)\n",
      "\n",
      "plotly>=5.0.0 instalado correctamente\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (6.3.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from plotly>=5.0.0) (2.7.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from plotly>=5.0.0) (25.0)\n",
      "\n",
      "\n",
      "============================================================\n",
      "Resumen del proceso de instalación:\n",
      "   Exitosas: 10\n",
      "   Fallidas: 0\n",
      "\n",
      "Entorno base configurado para sistemas LLM/RAG vehiculares\n",
      "plotly>=5.0.0 instalado correctamente\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (6.3.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from plotly>=5.0.0) (2.7.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\haranzales\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from plotly>=5.0.0) (25.0)\n",
      "\n",
      "\n",
      "============================================================\n",
      "Resumen del proceso de instalación:\n",
      "   Exitosas: 10\n",
      "   Fallidas: 0\n",
      "\n",
      "Entorno base configurado para sistemas LLM/RAG vehiculares\n"
     ]
    }
   ],
   "source": [
    "# Sección de instalación de dependencias\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "from typing import List\n",
    "\n",
    "def install_package(package: str) -> bool:\n",
    "    try:\n",
    "        # Usar subprocess.run para compatibilidad con versiones de Python donde\n",
    "        # Popen.__init__ no acepta capture_output en check_call indirectamente.\n",
    "        result = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", package],\n",
    "                             capture_output=True, text=True, check=True)\n",
    "        print(f\"{package} instalado correctamente\")\n",
    "        if result.stdout:\n",
    "            print(result.stdout)\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        # Mostrar salida y error para facilitar diagnóstico\n",
    "        stderr = e.stderr if hasattr(e, 'stderr') else None\n",
    "        stdout = e.stdout if hasattr(e, 'stdout') else None\n",
    "        print(f\"Error de instalación con {package}: returncode={getattr(e, 'returncode', None)}\")\n",
    "        if stdout:\n",
    "            print('STDOUT:\\n', stdout)\n",
    "        if stderr:\n",
    "            print('STDERR:\\n', stderr)\n",
    "        return False\n",
    "\n",
    "# Lista de dependencias críticas para el proyecto DECODE-EV\n",
    "dependencias_core = [\n",
    "    \"pandas>=1.5.0\",           # Manipulación de datasets CAN\n",
    "    \"numpy>=1.21.0\",           # Operaciones numéricas optimizadas\n",
    "    \"matplotlib>=3.5.0\",       # Visualización base\n",
    "    \"seaborn>=0.11.0\"          # Visualización estadística avanzada\n",
    "]\n",
    "\n",
    "dependencias_llm = [\n",
    "    \"langchain>=0.1.0\",        # Framework de orquestación RAG\n",
    "    \"langchain-community\",     # Componentes extendidos de LangChain\n",
    "    \"sentence-transformers\",   # Generación de embeddings semánticos\n",
    "    \"tiktoken\",               # Tokenización para modelos GPT\n",
    "    \"jsonlines\"              # Formato JSONL para datasets RAG\n",
    "]\n",
    "\n",
    "dependencias_visualizacion = [\n",
    "    \"plotly>=5.0.0\"           # Visualizaciones interactivas para análisis\n",
    "]\n",
    "\n",
    "# Instalación secuencial con verificación de éxito\n",
    "todas_dependencias = dependencias_core + dependencias_llm + dependencias_visualizacion\n",
    "instalaciones_exitosas = []\n",
    "instalaciones_fallidas = []\n",
    "\n",
    "print(\"Estado: Iniciando configuración del entorno DECODE-EV...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for paquete in todas_dependencias:\n",
    "    if install_package(paquete):\n",
    "        instalaciones_exitosas.append(paquete)\n",
    "    else:\n",
    "        instalaciones_fallidas.append(paquete)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Resumen del proceso de instalación:\")\n",
    "print(f\"   Exitosas: {len(instalaciones_exitosas)}\")\n",
    "print(f\"   Fallidas: {len(instalaciones_fallidas)}\")\n",
    "\n",
    "if instalaciones_fallidas:\n",
    "    print(f\"\\n Dependencias que requieren instalación manual:\")\n",
    "    for paquete in instalaciones_fallidas:\n",
    "        print(f\"   pip install {paquete}\")\n",
    "        \n",
    "print(\"\\nEntorno base configurado para sistemas LLM/RAG vehiculares\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "912eee67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 13:27:02,151 - INFO - jsonlines importado correctamente\n",
      "2025-10-06 13:27:03,050 - INFO - LangChain v0.1+ importado correctamente\n",
      "2025-10-06 13:27:03,053 - INFO - Estilo matplotlib 'seaborn-v0_8' aplicado exitosamente\n",
      "2025-10-06 13:27:03,054 - INFO - Paleta de colores vehicular configurada\n",
      "2025-10-06 13:27:03,050 - INFO - LangChain v0.1+ importado correctamente\n",
      "2025-10-06 13:27:03,053 - INFO - Estilo matplotlib 'seaborn-v0_8' aplicado exitosamente\n",
      "2025-10-06 13:27:03,054 - INFO - Paleta de colores vehicular configurada\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DECODE-EV: ENTORNO TÉCNICO CONFIGURADO\n",
      "======================================================================\n",
      "Pandas versión: 2.3.2\n",
      "NumPy versión: 2.3.3\n",
      "Matplotlib estilo: seaborn-v0_8\n",
      "Paleta de colores: Configurada\n",
      "JSONL soporte: Disponible\n",
      "LangChain soporte: Disponible\n",
      "======================================================================\n",
      "Sistema listo para procesamiento de datos CAN vehiculares\n",
      "Capacidades RAG/LLM: Habilitadas\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Importación estratégica de librerías\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Módulos para procesamiento de texto y análisis semántico\n",
    "import re\n",
    "from typing import Dict, List, Tuple, Optional, Union, Any\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "\n",
    "# Configuración de logging para debugging avanzado\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Importación segura de jsonlines con fallback automático\n",
    "def safe_import_jsonlines():\n",
    "    try:\n",
    "        import jsonlines\n",
    "        logger.info(\"jsonlines importado correctamente\")\n",
    "        return jsonlines\n",
    "    except ImportError:\n",
    "        logger.warning(\"jsonlines no disponible - iniciando instalación automática...\")\n",
    "        try:\n",
    "            import subprocess\n",
    "            import sys\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"jsonlines\"], \n",
    "                                capture_output=True)\n",
    "            import jsonlines\n",
    "            logger.info(\"jsonlines instalado e importado exitosamente\")\n",
    "            return jsonlines\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error en instalación automática de jsonlines: {e}\")\n",
    "            return None\n",
    "\n",
    "# Importación segura de LangChain con manejo de versiones\n",
    "def safe_import_langchain():\n",
    "    langchain_components = {}\n",
    "    \n",
    "    try:\n",
    "        # Intento de importación moderna (LangChain v0.1+)\n",
    "        from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "        from langchain_core.documents import Document\n",
    "        langchain_components['text_splitter'] = RecursiveCharacterTextSplitter\n",
    "        langchain_components['document'] = Document\n",
    "        logger.info(\"LangChain v0.1+ importado correctamente\")\n",
    "    except ImportError:\n",
    "        try:\n",
    "            # Fallback para versiones anteriores\n",
    "            from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "            from langchain.docstore.document import Document\n",
    "            langchain_components['text_splitter'] = RecursiveCharacterTextSplitter\n",
    "            langchain_components['document'] = Document\n",
    "            logger.info(\"LangChain versión clásica importada\")\n",
    "        except ImportError:\n",
    "            logger.warning(\"LangChain no disponible - funcionalidad RAG limitada\")\n",
    "            langchain_components = None\n",
    "    \n",
    "    return langchain_components\n",
    "\n",
    "# Ejecutar importaciones seguras\n",
    "jsonlines = safe_import_jsonlines()\n",
    "langchain_components = safe_import_langchain()\n",
    "\n",
    "# Configuración avanzada de visualización con múltiples fallbacks\n",
    "def configure_matplotlib_style():\n",
    "    estilos_preferidos = [\n",
    "        'seaborn-v0_8',      # Estilo moderno preferido\n",
    "        'seaborn-whitegrid',  # Alternativa limpia\n",
    "        'seaborn',           # Clásico\n",
    "        'ggplot',            # Alternativa colorida\n",
    "        'default'            # Fallback final\n",
    "    ]\n",
    "    \n",
    "    for estilo in estilos_preferidos:\n",
    "        try:\n",
    "            plt.style.use(estilo)\n",
    "            logger.info(f\"Estilo matplotlib '{estilo}' aplicado exitosamente\")\n",
    "            return estilo\n",
    "        except OSError:\n",
    "            continue\n",
    "    \n",
    "    logger.warning(\"Usando estilo matplotlib por defecto\")\n",
    "    return 'default'\n",
    "\n",
    "# Configuración de paleta de colores con optimización para datos vehiculares\n",
    "def configure_color_palette():\n",
    "    try:\n",
    "        # Paleta personalizada para redes CAN vehiculares\n",
    "        colores_can = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#592F2B']\n",
    "        sns.set_palette(colores_can)\n",
    "        logger.info(\"Paleta de colores vehicular configurada\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Error configurando paleta personalizada: {e}\")\n",
    "        try:\n",
    "            sns.set_palette(\"husl\")\n",
    "            logger.info(\"Paleta de colores estándar configurada\")\n",
    "            return True\n",
    "        except Exception:\n",
    "            logger.warning(\"Usando colores por defecto\")\n",
    "            return False\n",
    "\n",
    "# Ejecutar configuraciones\n",
    "estilo_aplicado = configure_matplotlib_style()\n",
    "paleta_configurada = configure_color_palette()\n",
    "\n",
    "# Configuración de warnings con categorización\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)  # Suppress pandas warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)    # Suppress matplotlib warnings\n",
    "warnings.filterwarnings('default', category=DeprecationWarning)  # Show deprecation warnings\n",
    "\n",
    "# Configuración global de pandas para datasets grandes\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "# Configuración de numpy para reproducibilidad\n",
    "np.random.seed(42)\n",
    "\n",
    "# Verificación de configuración del entorno\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DECODE-EV: ENTORNO TÉCNICO CONFIGURADO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Pandas versión: {pd.__version__}\")\n",
    "print(f\"NumPy versión: {np.__version__}\")\n",
    "print(f\"Matplotlib estilo: {estilo_aplicado}\")\n",
    "print(f\"Paleta de colores: {'Configurada' if paleta_configurada else '❌ Por defecto'}\")\n",
    "print(f\"JSONL soporte: {'Disponible' if jsonlines else 'No disponible'}\")\n",
    "print(f\"LangChain soporte: {'Disponible' if langchain_components else 'No disponible'}\")\n",
    "print(\"=\"*70)\n",
    "print(\"Sistema listo para procesamiento de datos CAN vehiculares\")\n",
    "print(\"Capacidades RAG/LLM: Habilitadas\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ddae24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERIFICACIÓN DE DEPENDENCIAS:\n",
      "----------------------------------------\n",
      "pandas      : 2.3.2\n",
      "numpy       : 2.3.3\n",
      "matplotlib  : disponible\n",
      "seaborn     : 0.13.2\n",
      "plotly      : disponible\n",
      "jsonlines   : Disponible\n",
      "langchain   : Disponible\n",
      "----------------------------------------\n",
      "Estado: Entorno listo para análisis CAN\n"
     ]
    }
   ],
   "source": [
    "# Verificación de dependencias y versiones\n",
    "def verificar_entorno():\n",
    "    \n",
    "    dependencias = {\n",
    "        'pandas': pd.__version__,\n",
    "        'numpy': np.__version__,\n",
    "        'matplotlib': plt.__version__ if hasattr(plt, '__version__') else \"disponible\",\n",
    "        'seaborn': sns.__version__,\n",
    "        'plotly': px.__version__ if hasattr(px, '__version__') else \"disponible\",\n",
    "    }\n",
    "    \n",
    "    print(\"VERIFICACIÓN DE DEPENDENCIAS:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for lib, version in dependencias.items():\n",
    "        print(f\"{lib:<12}: {version}\")\n",
    "    \n",
    "    # Verificar jsonlines\n",
    "    try:\n",
    "        import jsonlines\n",
    "        print(f\"{'jsonlines':<12}: Disponible\")\n",
    "    except ImportError:\n",
    "        print(f\"{'jsonlines':<12}: No Disponible\")\n",
    "    \n",
    "    # Verificar LangChain\n",
    "    try:\n",
    "        from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "        print(f\"{'langchain':<12}: Disponible\")\n",
    "    except ImportError:\n",
    "        print(f\"{'langchain':<12}: No Disponible (opcional)\")\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(\"Estado: Entorno listo para análisis CAN\")\n",
    "\n",
    "# Ejecutar verificación\n",
    "verificar_entorno()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efc7f6f",
   "metadata": {},
   "source": [
    "## 2. Arquitectura de Datos y Estructuras Semánticas para Sistemas RAG \n",
    "\n",
    "### Fundamentación Teórica: Modelado de Datos CAN para LLM\n",
    "\n",
    "La transformación de datos vehiculares CAN hacia representaciones compatibles con sistemas RAG requiere una arquitectura de datos especializada que preserve tanto la precisión técnica como la accesibilidad semántica. La metodología implementada se fundamenta en principios de **ingeniería de conocimiento** aplicados al dominio automotriz.\n",
    "\n",
    "### Diseño de Estructuras de Datos Orientadas a Conocimiento\n",
    "\n",
    "La arquitectura propuesta implementa un **modelo conceptual jerárquico** que organiza la información CAN en múltiples niveles de abstracción:\n",
    "\n",
    "1. **Nivel de Señal:** Datos numéricos crudos con metadatos técnicos directamente obtenidos de pruebas en la unidad. \n",
    "2. **Nivel de Evento:** Agregaciones semánticamente coherentes de señales\n",
    "3. **Nivel de Contexto:** Información situacional y operativa del vehículo\n",
    "4. **Nivel de Conocimiento:** Representaciones textuales enriquecidas para RAG\n",
    "\n",
    "### Justificación Metodológica para Estructuras Dataclass\n",
    "\n",
    "El equipo de trabajo considera que la utilización de **dataclasses** de Python para modelado de datos CAN ofrece ventajas específicas para sistemas LLM:\n",
    "\n",
    "- **Validación automática de tipos:** Garantiza consistencia en representaciones semánticas\n",
    "- **Serialización controlada:** Facilita conversión a formatos RAG (JSONL)\n",
    "- **Inmutabilidad opcional:** Preserva integridad de metadatos críticos\n",
    "- **Introspección mejorada:** Facilita debugging y análisis de calidad de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2345a488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estructuras de datos semánticas definidas:\n",
      "CANEventMetadata: Metadatos enriquecidos de eventos\n",
      "CANSignalDescription: Descripciones textuales de señales\n",
      "RAGDatasetEntry: Entradas optimizadas para sistemas RAG\n",
      "\n",
      " Arquitectura de datos lista para procesamiento CAN→RAG\n"
     ]
    }
   ],
   "source": [
    "# Definición de estructuras de datos especializadas para modelado semántico CAN\n",
    "# Implementación orientada a conocimiento para sistemas RAG vehiculares\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional, Union, Any\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "@dataclass\n",
    "class CANEventMetadata:\n",
    "    \"\"\"\n",
    "    Estructura de metadatos enriquecidos para eventos vehiculares CAN.\n",
    "    \n",
    "    Diseñada específicamente para sistemas RAG que requieren contextualización\n",
    "    semántica precisa de eventos temporales complejos.\n",
    "    \n",
    "    Attributes:\n",
    "        timestamp_inicio: Marca temporal de inicio del evento (ISO 8601)\n",
    "        timestamp_fin: Marca temporal de finalización del evento \n",
    "        duracion_segundos: Duración del evento en segundos (precisión de milisegundos)\n",
    "        red_can: Identificador de red CAN involucrada\n",
    "        senales_involucradas: Lista de señales CAN participantes en el evento\n",
    "        evento_vehiculo: Clasificación semántica del evento\n",
    "        intensidad: Nivel de intensidad categorizado\n",
    "        contexto_operativo: Contexto situacional del vehículo\n",
    "        confianza_clasificacion: Score de confianza en la clasificación automática\n",
    "    \"\"\"\n",
    "    timestamp_inicio: str\n",
    "    timestamp_fin: str\n",
    "    duracion_segundos: float\n",
    "    red_can: str  # CAN_EV, CAN_CATL, CAN_CARROC, AUX_CHG\n",
    "    senales_involucradas: List[str]\n",
    "    evento_vehiculo: str  # \"aceleracion\", \"frenado\", \"carga\", \"idle\", \"mantenimiento\"\n",
    "    intensidad: str  # \"bajo\", \"medio\", \"alto\", \"critico\"\n",
    "    contexto_operativo: str  # \"ciudad\", \"carretera\", \"estacionado\", \"carga\"\n",
    "    confianza_clasificacion: float = field(default=0.0)  # 0.0 - 1.0\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Serializa metadatos a diccionario JSON-compatible.\n",
    "        Optimizado para ingesta en sistemas RAG.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"timestamp_inicio\": self.timestamp_inicio,\n",
    "            \"timestamp_fin\": self.timestamp_fin,\n",
    "            \"duracion_segundos\": self.duracion_segundos,\n",
    "            \"red_can\": self.red_can,\n",
    "            \"senales_involucradas\": self.senales_involucradas,\n",
    "            \"evento_vehiculo\": self.evento_vehiculo,\n",
    "            \"intensidad\": self.intensidad,\n",
    "            \"contexto_operativo\": self.contexto_operativo,\n",
    "            \"confianza_clasificacion\": self.confianza_clasificacion\n",
    "        }\n",
    "    \n",
    "    def generate_semantic_tags(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Genera tags semánticos para facilitar recuperación en sistemas RAG.\n",
    "        Implementa estrategia de tageo multi-dimensional.\n",
    "        \"\"\"\n",
    "        tags = [\n",
    "            f\"red_{self.red_can.lower()}\",\n",
    "            f\"evento_{self.evento_vehiculo}\",\n",
    "            f\"intensidad_{self.intensidad}\",\n",
    "            f\"contexto_{self.contexto_operativo}\",\n",
    "            f\"duracion_{self._categorize_duration()}\"\n",
    "        ]\n",
    "        \n",
    "        # Tags adicionales basados en señales involucradas\n",
    "        if any('voltaje' in senal.lower() for senal in self.senales_involucradas):\n",
    "            tags.append(\"sistema_electrico\")\n",
    "        if any('temperatura' in senal.lower() for senal in self.senales_involucradas):\n",
    "            tags.append(\"gestion_termica\")\n",
    "        if any('corriente' in senal.lower() for senal in self.senales_involucradas):\n",
    "            tags.append(\"consumo_energetico\")\n",
    "            \n",
    "        return tags\n",
    "    \n",
    "    def _categorize_duration(self) -> str:\n",
    "        \"\"\"Categoriza duración del evento para tageo semántico.\"\"\"\n",
    "        if self.duracion_segundos < 1:\n",
    "            return \"instantaneo\"\n",
    "        elif self.duracion_segundos < 10:\n",
    "            return \"corto\"\n",
    "        elif self.duracion_segundos < 60:\n",
    "            return \"medio\"\n",
    "        else:\n",
    "            return \"prolongado\"\n",
    "\n",
    "@dataclass\n",
    "class CANSignalDescription:\n",
    "    \"\"\"\n",
    "    Estructura para descripciones textuales enriquecidas de señales CAN.\n",
    "    \n",
    "    Optimizada para generación de contenido RAG con preservación\n",
    "    de precisión técnica y accesibilidad conversacional.\n",
    "    \"\"\"\n",
    "    signal_name: str\n",
    "    technical_description: str\n",
    "    conversational_description: str\n",
    "    unit: str\n",
    "    normal_range: str\n",
    "    critical_thresholds: Dict[str, float]\n",
    "    semantic_category: str  # \"sistema_energia\", \"control_motor\", \"diagnostico\", etc.\n",
    "    documentation_source: str  # \"DBC\", \"J1939\", \"INFERIDO\", \"MANUAL\"\n",
    "    quality_score: float = field(default=0.0)  # Métrica de calidad de descripción\n",
    "    \n",
    "    def to_rag_document(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Convierte a formato de documento RAG con metadatos estructurados.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"content\": self.technical_description,\n",
    "            \"metadata\": {\n",
    "                \"signal_name\": self.signal_name,\n",
    "                \"conversational_description\": self.conversational_description,\n",
    "                \"unit\": self.unit,\n",
    "                \"normal_range\": self.normal_range,\n",
    "                \"critical_thresholds\": self.critical_thresholds,\n",
    "                \"semantic_category\": self.semantic_category,\n",
    "                \"documentation_source\": self.documentation_source,\n",
    "                \"quality_score\": self.quality_score,\n",
    "                \"document_type\": \"can_signal_description\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "@dataclass \n",
    "class RAGDatasetEntry:\n",
    "    \"\"\"\n",
    "    Entrada individual del dataset RAG optimizada para sistemas conversacionales.\n",
    "    \n",
    "    Implementa estructura unificada que combina metadatos CAN, \n",
    "    descripciones textuales y contexto semántico.\n",
    "    \"\"\"\n",
    "    id: str\n",
    "    content: str  # Descripción textual principal\n",
    "    metadata: CANEventMetadata\n",
    "    signal_descriptions: List[CANSignalDescription] \n",
    "    embedding_vector: Optional[List[float]] = field(default=None)\n",
    "    quality_metrics: Dict[str, float] = field(default_factory=dict)\n",
    "    \n",
    "    def to_jsonl_entry(self) -> str:\n",
    "        \"\"\"\n",
    "        Serializa entrada a formato JSONL para sistemas RAG.\n",
    "        Optimizado para carga eficiente en sistemas de vectores.\n",
    "        \"\"\"\n",
    "        entry = {\n",
    "            \"id\": self.id,\n",
    "            \"content\": self.content,\n",
    "            \"metadata\": self.metadata.to_dict(),\n",
    "            \"signal_descriptions\": [desc.to_rag_document() for desc in self.signal_descriptions],\n",
    "            \"quality_metrics\": self.quality_metrics,\n",
    "            \"semantic_tags\": self.metadata.generate_semantic_tags()\n",
    "        }\n",
    "        \n",
    "        # Incluir embedding vector si está disponible\n",
    "        if self.embedding_vector is not None:\n",
    "            entry[\"embedding_vector\"] = self.embedding_vector\n",
    "            \n",
    "        return json.dumps(entry, ensure_ascii=False)\n",
    "\n",
    "# Ejemplo de inicialización de estructuras con datos de prueba\n",
    "print(\"Estructuras de datos semánticas definidas:\")\n",
    "print(\"CANEventMetadata: Metadatos enriquecidos de eventos\")\n",
    "print(\"CANSignalDescription: Descripciones textuales de señales\")   \n",
    "print(\"RAGDatasetEntry: Entradas optimizadas para sistemas RAG\")\n",
    "print(\"\\n Arquitectura de datos lista para procesamiento CAN→RAG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9876cf",
   "metadata": {},
   "source": [
    "## 3. Procesamiento de Archivos DBC y BLF Reales\n",
    "\n",
    "**Sistema de carga de datos vehiculares CAN desde archivos reales:**\n",
    "- Se cargan archivos DBC de las redes CAN CATL (Baterías) y EV (Tracción)\n",
    "- Se procesan logs BLF grabados durante operación real del vehículo\n",
    "- **Solo datos reales** - sin simulaciones ni datos sintéticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78413259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTALANDO DEPENDENCIAS PARA PROCESAMIENTO CAN REAL...\n",
      "============================================================\n",
      "cantools instalado correctamente\n",
      "cantools instalado correctamente\n",
      "python-can instalado correctamente\n",
      "python-can instalado correctamente\n",
      "asammdf instalado correctamente\n",
      "Todas las dependencias CAN instaladas correctamente\n",
      "\n",
      "SISTEMA DE PROCESAMIENTO REAL CONFIGURADO\n",
      "Solo datos reales - sin simulaciones\n",
      "Dependencias CAN instaladas y verificadas\n",
      "asammdf instalado correctamente\n",
      "Todas las dependencias CAN instaladas correctamente\n",
      "\n",
      "SISTEMA DE PROCESAMIENTO REAL CONFIGURADO\n",
      "Solo datos reales - sin simulaciones\n",
      "Dependencias CAN instaladas y verificadas\n"
     ]
    }
   ],
   "source": [
    "# === INSTALACIÓN AUTOMÁTICA DE DEPENDENCIAS CAN ===\n",
    "import os\n",
    "import hashlib\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "print(\"INSTALANDO DEPENDENCIAS PARA PROCESAMIENTO CAN REAL...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def install_can_dependencies():\n",
    "    \"\"\"Instala dependencias críticas para procesamiento real de archivos CAN\"\"\"\n",
    "    dependencias_can = [\n",
    "        \"cantools\",      # Lectura de archivos DBC\n",
    "        \"python-can\",    # Lectura de archivos BLF\n",
    "        \"asammdf\"        # Alternativa para archivos MDF/BLF\n",
    "    ]\n",
    "    \n",
    "    instalaciones_exitosas = 0\n",
    "    \n",
    "    for dep in dependencias_can:\n",
    "        try:\n",
    "            result = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", dep], \n",
    "                                 capture_output=True, text=True, check=True)\n",
    "            print(f\"{dep} instalado correctamente\")\n",
    "            instalaciones_exitosas += 1\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error instalando {dep}\")\n",
    "            if e.stderr:\n",
    "                print(f\"   Error: {e.stderr}\")\n",
    "    \n",
    "    if instalaciones_exitosas == len(dependencias_can):\n",
    "        print(\"Todas las dependencias CAN instaladas correctamente\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Solo {instalaciones_exitosas}/{len(dependencias_can)} dependencias instaladas\")\n",
    "        return False\n",
    "\n",
    "# Ejecutar instalación automática\n",
    "dependencias_instaladas = install_can_dependencies()\n",
    "\n",
    "if not dependencias_instaladas:\n",
    "    print(\"ERROR CRÍTICO: Sin las dependencias CAN no se pueden procesar archivos reales\")\n",
    "    print(\"   Instale manualmente: pip install cantools python-can asammdf\")\n",
    "    raise ImportError(\"Dependencias CAN requeridas no disponibles\")\n",
    "\n",
    "# === FUNCIONES DE PROCESAMIENTO REAL (SIN SIMULACIÓN) ===\n",
    "\n",
    "def procesar_archivos_dbc_solo_reales(archivos_dbc: List[str]) -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    Procesa archivos DBC REALES únicamente\n",
    "    NO incluye fallbacks a datos simulados\n",
    "    \"\"\"\n",
    "    definiciones_dbc = {}\n",
    "    \n",
    "    print(\"\\n PROCESANDO ARCHIVOS DBC REALES:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for archivo_dbc in archivos_dbc:\n",
    "        nombre_archivo = os.path.basename(archivo_dbc)\n",
    "        print(f\"Procesando: {nombre_archivo}\")\n",
    "        \n",
    "        try:\n",
    "            # Usar cantools para leer DBC real\n",
    "            import cantools\n",
    "            db = cantools.database.load_file(archivo_dbc)\n",
    "            \n",
    "            señales_extraidas = {}\n",
    "            for mensaje in db.messages:\n",
    "                for senal in mensaje.signals:\n",
    "                    señales_extraidas[senal.name] = {\n",
    "                        'unidad': getattr(senal, 'unit', ''),\n",
    "                        'factor': getattr(senal, 'scale', 1),\n",
    "                        'offset': getattr(senal, 'offset', 0),\n",
    "                        'descripcion': getattr(senal, 'comment', f'Señal CAN: {senal.name}'),\n",
    "                        'min': getattr(senal, 'minimum', None),\n",
    "                        'max': getattr(senal, 'maximum', None),\n",
    "                        'mensaje_id': f'0x{mensaje.frame_id:X}',\n",
    "                        'start_bit': senal.start,\n",
    "                        'length': senal.length\n",
    "                    }\n",
    "            \n",
    "            definiciones_dbc[nombre_archivo] = {\n",
    "                'señales': señales_extraidas,\n",
    "                'ruta': archivo_dbc,\n",
    "                'procesado': True,\n",
    "                'metodo': 'cantools_real'\n",
    "            }\n",
    "            \n",
    "            print(f\"{len(señales_extraidas)} señales extraídas del DBC real\")\n",
    "            \n",
    "        except ImportError:\n",
    "            print(f\"ERROR: cantools no disponible para {nombre_archivo}\")\n",
    "            print(\"Instale: pip install cantools\")\n",
    "            raise ImportError(f\"cantools requerido para procesar {nombre_archivo}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ERROR procesando {nombre_archivo}: {str(e)}\")\n",
    "            raise Exception(f\"Error procesando DBC real: {str(e)}\")\n",
    "    \n",
    "    return definiciones_dbc\n",
    "\n",
    "def cargar_archivo_blf_solo_real(archivo_blf: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Carga archivo BLF REAL únicamente\n",
    "    NO incluye fallbacks a datos simulados\n",
    "    \"\"\"\n",
    "    nombre_archivo = os.path.basename(archivo_blf)\n",
    "    \n",
    "    try:\n",
    "        import can\n",
    "        \n",
    "        print(f\"Leyendo BLF real: {nombre_archivo}\")\n",
    "        \n",
    "        # Leer archivo BLF real\n",
    "        mensajes = []\n",
    "        with can.BLFReader(archivo_blf) as reader:\n",
    "            for i, msg in enumerate(reader):\n",
    "                # Procesar todos los mensajes (eliminar límite artificial)\n",
    "                mensajes.append({\n",
    "                    'timestamp': msg.timestamp,\n",
    "                    'arbitration_id': f'0x{msg.arbitration_id:X}',\n",
    "                    'data': msg.data.hex() if msg.data else '',\n",
    "                    'dlc': msg.dlc if hasattr(msg, 'dlc') else len(msg.data) if msg.data else 0,\n",
    "                    'is_extended': msg.is_extended_id if hasattr(msg, 'is_extended_id') else False,\n",
    "                    'channel': getattr(msg, 'channel', 0)\n",
    "                })\n",
    "                \n",
    "                # Progreso cada 50k mensajes\n",
    "                if i > 0 and i % 50000 == 0:\n",
    "                    print(f\"      Procesados {i:,} mensajes...\")\n",
    "        \n",
    "        if not mensajes:\n",
    "            raise ValueError(f\"No se encontraron mensajes CAN en {nombre_archivo}\")\n",
    "        \n",
    "        df = pd.DataFrame(mensajes)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "        \n",
    "        print(f\"BLF real cargado: {len(df):,} mensajes CAN\")\n",
    "        return df\n",
    "        \n",
    "    except ImportError:\n",
    "        print(f\"ERROR: python-can no disponible para {nombre_archivo}\")\n",
    "        print(\"Instale: pip install python-can\")\n",
    "        raise ImportError(f\"python-can requerido para procesar {nombre_archivo}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR leyendo BLF real {nombre_archivo}: {e}\")\n",
    "        raise Exception(f\"Error procesando BLF real: {str(e)}\")\n",
    "\n",
    "def cargar_datos_solo_reales(archivos_blf: List[str], definiciones_dbc: Dict[str, Dict]) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Carga datos REALES únicamente - sin fallbacks simulados\n",
    "    \"\"\"\n",
    "    datasets_procesados = {}\n",
    "    \n",
    "    print(\"\\nPROCESANDO ARCHIVOS DE DATOS REALES:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for archivo_blf in archivos_blf:\n",
    "        nombre_archivo = os.path.basename(archivo_blf)\n",
    "        extension = os.path.splitext(archivo_blf)[1].lower()\n",
    "        \n",
    "        print(f\"Procesando: {nombre_archivo}\")\n",
    "        \n",
    "        try:\n",
    "            # Cargar datos según formato\n",
    "            if extension == '.blf':\n",
    "                df = cargar_archivo_blf_solo_real(archivo_blf)\n",
    "                \n",
    "            elif extension == '.csv':\n",
    "                df = pd.read_csv(archivo_blf)\n",
    "                print(f\"CSV cargado: {len(df):,} registros\")\n",
    "                \n",
    "            elif extension in ['.xlsx', '.xls']:\n",
    "                df = pd.read_excel(archivo_blf)\n",
    "                print(f\"Excel cargado: {len(df):,} registros\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"Formato {extension} no soportado\")\n",
    "                print(\"       Formatos admitidos: .blf, .csv, .xlsx, .xls\")\n",
    "                continue\n",
    "            \n",
    "            # Aplicar definiciones DBC\n",
    "            df_procesado = aplicar_definiciones_dbc_real(df, definiciones_dbc, nombre_archivo)\n",
    "            \n",
    "            # Identificar red CAN\n",
    "            red_can = identificar_red_can(nombre_archivo)\n",
    "            datasets_procesados[red_can] = df_procesado\n",
    "            \n",
    "            print(f\" Procesado como red: {red_can}\")\n",
    "            print(f\"      Registros: {len(df_procesado):,} | Columnas: {len(df_procesado.columns)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ERROR procesando {nombre_archivo}: {str(e)}\")\n",
    "            raise Exception(f\"Error crítico procesando datos reales: {str(e)}\")\n",
    "    \n",
    "    return datasets_procesados\n",
    "\n",
    "def aplicar_definiciones_dbc_real(df: pd.DataFrame, definiciones_dbc: Dict, nombre_archivo: str) -> pd.DataFrame:\n",
    "    \"\"\"Aplica definiciones DBC reales a los datos cargados\"\"\"\n",
    "    df_procesado = df.copy()\n",
    "    \n",
    "    # Buscar definiciones DBC aplicables\n",
    "    aplicaciones = 0\n",
    "    for archivo_dbc, definiciones in definiciones_dbc.items():\n",
    "        if definiciones['procesado']:\n",
    "            señales_dbc = definiciones['señales']\n",
    "            \n",
    "            # Aplicar factores de escala y unidades a columnas existentes\n",
    "            for columna in df_procesado.columns:\n",
    "                if columna in señales_dbc:\n",
    "                    info_senal = señales_dbc[columna]\n",
    "                    factor = info_senal.get('factor', 1)\n",
    "                    offset = info_senal.get('offset', 0)\n",
    "                    \n",
    "                    if pd.api.types.is_numeric_dtype(df_procesado[columna]):\n",
    "                        if factor != 1 or offset != 0:\n",
    "                            df_procesado[columna] = (df_procesado[columna] * factor) + offset\n",
    "                            aplicaciones += 1\n",
    "    \n",
    "    if aplicaciones > 0:\n",
    "        print(f\"Aplicadas {aplicaciones} definiciones DBC\")\n",
    "    \n",
    "    return df_procesado\n",
    "\n",
    "def identificar_red_can(nombre_archivo: str) -> str:\n",
    "    \"\"\"Identifica la red CAN basado en el nombre del archivo\"\"\"\n",
    "    nombre_lower = nombre_archivo.lower()\n",
    "    \n",
    "    if 'ev' in nombre_lower or 'motor' in nombre_lower or 'traction' in nombre_lower:\n",
    "        return 'CAN_EV'\n",
    "    elif 'catl' in nombre_lower or 'bateria' in nombre_lower or 'battery' in nombre_lower or 'bms' in nombre_lower:\n",
    "        return 'CAN_CATL'\n",
    "    elif 'carroc' in nombre_lower or 'body' in nombre_lower or 'puerta' in nombre_lower or 'door' in nombre_lower:\n",
    "        return 'CAN_CARROC'\n",
    "    elif 'aux' in nombre_lower or 'chg' in nombre_lower or 'carga' in nombre_lower or 'charge' in nombre_lower:\n",
    "        return 'AUX_CHG'\n",
    "    else:\n",
    "        # Usar hash del nombre para generar identificador único consistente\n",
    "        hash_obj = hashlib.md5(nombre_archivo.encode())\n",
    "        return f'CAN_CUSTOM_{hash_obj.hexdigest()[:8].upper()}'\n",
    "\n",
    "# Funciones de selección de archivos (reutilizadas sin cambios)\n",
    "def seleccionar_archivos_dbc() -> List[str]:\n",
    "    \"\"\"Selecciona múltiples archivos DBC usando interfaz gráfica\"\"\"\n",
    "    \n",
    "    print(\"SELECCIÓN DE ARCHIVOS DBC (Definiciones de Señales)\")\n",
    "    print(\"=\" * 55)\n",
    "    print(\"Los archivos DBC contienen:\")\n",
    "    print(\"- Definiciones de señales CAN reales\")\n",
    "    print(\"- Unidades de medida y factores de escalado\")\n",
    "    print(\"- Descripciones funcionales\")\n",
    "    print(\"- Metadatos técnicos\\n\")\n",
    "    \n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    \n",
    "    archivos_dbc = filedialog.askopenfilenames(\n",
    "        title=\"Seleccionar archivos DBC (Definiciones CAN)\",\n",
    "        filetypes=[\n",
    "            (\"DBC files\", \"*.dbc\"),\n",
    "            (\"All files\", \"*.*\")\n",
    "        ],\n",
    "        initialdir=os.path.expanduser(\"~\")\n",
    "    )\n",
    "    \n",
    "    root.destroy()\n",
    "    \n",
    "    if archivos_dbc:\n",
    "        print(f\"{len(archivos_dbc)} archivo(s) DBC seleccionado(s):\")\n",
    "        for i, archivo in enumerate(archivos_dbc, 1):\n",
    "            nombre = os.path.basename(archivo)\n",
    "            print(f\"   {i}. {nombre}\")\n",
    "    else:\n",
    "        print(\"No se seleccionaron archivos DBC\")\n",
    "        raise ValueError(\"Se requieren archivos DBC para procesar datos reales\")\n",
    "    \n",
    "    return list(archivos_dbc)\n",
    "\n",
    "def seleccionar_archivos_blf() -> List[str]:\n",
    "    \"\"\"Selecciona múltiples archivos BLF/datos usando interfaz gráfica\"\"\"\n",
    "    \n",
    "    print(\"\\n SELECCIÓN DE ARCHIVOS DE DATOS (Logs del Vehículo)\")\n",
    "    print(\"=\" * 55)\n",
    "    print(\"Formatos soportados:\")\n",
    "    print(\"- BLF: Logs binarios del vehículo (recomendado)\")\n",
    "    print(\"- CSV: Datos procesados\")\n",
    "    print(\"- Excel: Datos tabulares\\n\")\n",
    "    \n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    \n",
    "    archivos_blf = filedialog.askopenfilenames(\n",
    "        title=\"Seleccionar archivos de datos del vehículo\",\n",
    "        filetypes=[\n",
    "            (\"BLF files\", \"*.blf\"),\n",
    "            (\"CSV files\", \"*.csv\"),\n",
    "            (\"Excel files\", \"*.xlsx *.xls\"),\n",
    "            (\"All files\", \"*.*\")\n",
    "        ],\n",
    "        initialdir=os.path.expanduser(\"~\")\n",
    "    )\n",
    "    \n",
    "    root.destroy()\n",
    "    \n",
    "    if archivos_blf:\n",
    "        print(f\"{len(archivos_blf)} archivo(s) de datos seleccionado(s):\")\n",
    "        for i, archivo in enumerate(archivos_blf, 1):\n",
    "            nombre = os.path.basename(archivo)\n",
    "            extension = os.path.splitext(archivo)[1].lower()\n",
    "            tipo_archivo = {\n",
    "                '.blf': 'BLF (Log binario)',\n",
    "                '.csv': 'CSV (Procesado)',\n",
    "                '.xlsx': 'Excel (Procesado)',\n",
    "                '.xls': 'Excel (Procesado)'\n",
    "            }.get(extension, 'Desconocido')\n",
    "            print(f\"   {i}. {nombre} - {tipo_archivo}\")\n",
    "    else:\n",
    "        print(\"No se seleccionaron archivos de datos\")\n",
    "        raise ValueError(\"Se requieren archivos de datos del vehículo para el análisis\")\n",
    "    \n",
    "    return list(archivos_blf)\n",
    "\n",
    "print(\"\\nSISTEMA DE PROCESAMIENTO REAL CONFIGURADO\")\n",
    "print(\"Solo datos reales - sin simulaciones\")\n",
    "print(\"Dependencias CAN instaladas y verificadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "465f69e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SISTEMA DE PROCESAMIENTO CAN - DATOS REALES ÚNICAMENTE\n",
      "=================================================================\n",
      "CONFIGURACIÓN:\n",
      "- Solo datos reales del vehículo\n",
      "- Archivos DBC y BLF auténticos\n",
      "- Sin simulaciones ni datos sintéticos\n",
      "- Procesamiento directo desde operación vehicular\n",
      "\n",
      "CARGA DE DEFINICIONES DBC REALES\n",
      "SELECCIÓN DE ARCHIVOS DBC (Definiciones de Señales)\n",
      "=======================================================\n",
      "Los archivos DBC contienen:\n",
      "- Definiciones de señales CAN reales\n",
      "- Unidades de medida y factores de escalado\n",
      "- Descripciones funcionales\n",
      "- Metadatos técnicos\n",
      "\n",
      "2 archivo(s) DBC seleccionado(s):\n",
      "   1. IP_JZ - CAN CATL.dbc\n",
      "   2. IP_JZ - CAN EV.DBC\n",
      "Procesando archivos DBC seleccionados...\n",
      "\n",
      " PROCESANDO ARCHIVOS DBC REALES:\n",
      "----------------------------------------\n",
      "Procesando: IP_JZ - CAN CATL.dbc\n",
      "2 archivo(s) DBC seleccionado(s):\n",
      "   1. IP_JZ - CAN CATL.dbc\n",
      "   2. IP_JZ - CAN EV.DBC\n",
      "Procesando archivos DBC seleccionados...\n",
      "\n",
      " PROCESANDO ARCHIVOS DBC REALES:\n",
      "----------------------------------------\n",
      "Procesando: IP_JZ - CAN CATL.dbc\n",
      "159 señales extraídas del DBC real\n",
      "Procesando: IP_JZ - CAN EV.DBC\n",
      "159 señales extraídas del DBC real\n",
      "Procesando: IP_JZ - CAN EV.DBC\n",
      "1344 señales extraídas del DBC real\n",
      "\n",
      "RESUMEN DBC:\n",
      "   Archivos procesados: 2\n",
      "   Total señales definidas: 1503\n",
      "IP_JZ - CAN CATL.dbc: 159 señales\n",
      "IP_JZ - CAN EV.DBC: 1344 señales\n",
      "\n",
      " CARGA DE DATOS VEHICULARES REALES\n",
      "\n",
      " SELECCIÓN DE ARCHIVOS DE DATOS (Logs del Vehículo)\n",
      "=======================================================\n",
      "Formatos soportados:\n",
      "- BLF: Logs binarios del vehículo (recomendado)\n",
      "- CSV: Datos procesados\n",
      "- Excel: Datos tabulares\n",
      "\n",
      "1344 señales extraídas del DBC real\n",
      "\n",
      "RESUMEN DBC:\n",
      "   Archivos procesados: 2\n",
      "   Total señales definidas: 1503\n",
      "IP_JZ - CAN CATL.dbc: 159 señales\n",
      "IP_JZ - CAN EV.DBC: 1344 señales\n",
      "\n",
      " CARGA DE DATOS VEHICULARES REALES\n",
      "\n",
      " SELECCIÓN DE ARCHIVOS DE DATOS (Logs del Vehículo)\n",
      "=======================================================\n",
      "Formatos soportados:\n",
      "- BLF: Logs binarios del vehículo (recomendado)\n",
      "- CSV: Datos procesados\n",
      "- Excel: Datos tabulares\n",
      "\n",
      "5 archivo(s) de datos seleccionado(s):\n",
      "   1. Logging_2025-09-12_07-17-31.blf - BLF (Log binario)\n",
      "   2. Logging_2025-09-12_07-28-31.blf - BLF (Log binario)\n",
      "   3. Logging_2025-09-12_07-43-57.blf - BLF (Log binario)\n",
      "   4. Logging_2025-09-12_07-59-10.blf - BLF (Log binario)\n",
      "   5. Logging_2025-09-12_08-19-48.blf - BLF (Log binario)\n",
      " Procesando archivos de datos seleccionados...\n",
      "\n",
      "PROCESANDO ARCHIVOS DE DATOS REALES:\n",
      "--------------------------------------------------\n",
      "Procesando: Logging_2025-09-12_07-17-31.blf\n",
      "Leyendo BLF real: Logging_2025-09-12_07-17-31.blf\n",
      "5 archivo(s) de datos seleccionado(s):\n",
      "   1. Logging_2025-09-12_07-17-31.blf - BLF (Log binario)\n",
      "   2. Logging_2025-09-12_07-28-31.blf - BLF (Log binario)\n",
      "   3. Logging_2025-09-12_07-43-57.blf - BLF (Log binario)\n",
      "   4. Logging_2025-09-12_07-59-10.blf - BLF (Log binario)\n",
      "   5. Logging_2025-09-12_08-19-48.blf - BLF (Log binario)\n",
      " Procesando archivos de datos seleccionados...\n",
      "\n",
      "PROCESANDO ARCHIVOS DE DATOS REALES:\n",
      "--------------------------------------------------\n",
      "Procesando: Logging_2025-09-12_07-17-31.blf\n",
      "Leyendo BLF real: Logging_2025-09-12_07-17-31.blf\n",
      "      Procesados 50,000 mensajes...\n",
      "      Procesados 50,000 mensajes...\n",
      "      Procesados 100,000 mensajes...\n",
      "      Procesados 100,000 mensajes...\n",
      "      Procesados 150,000 mensajes...\n",
      "      Procesados 150,000 mensajes...\n",
      "      Procesados 200,000 mensajes...\n",
      "      Procesados 200,000 mensajes...\n",
      "      Procesados 250,000 mensajes...\n",
      "      Procesados 300,000 mensajes...\n",
      "      Procesados 250,000 mensajes...\n",
      "      Procesados 300,000 mensajes...\n",
      "      Procesados 350,000 mensajes...\n",
      "      Procesados 400,000 mensajes...\n",
      "      Procesados 350,000 mensajes...\n",
      "      Procesados 400,000 mensajes...\n",
      "      Procesados 450,000 mensajes...\n",
      "      Procesados 450,000 mensajes...\n",
      "      Procesados 500,000 mensajes...\n",
      "      Procesados 500,000 mensajes...\n",
      "      Procesados 550,000 mensajes...\n",
      "      Procesados 550,000 mensajes...\n",
      "      Procesados 600,000 mensajes...\n",
      "      Procesados 600,000 mensajes...\n",
      "BLF real cargado: 636,609 mensajes CAN\n",
      " Procesado como red: CAN_CUSTOM_03F69071\n",
      "      Registros: 636,609 | Columnas: 6\n",
      "Procesando: Logging_2025-09-12_07-28-31.blf\n",
      "Leyendo BLF real: Logging_2025-09-12_07-28-31.blf\n",
      "      Procesados 50,000 mensajes...\n",
      "BLF real cargado: 636,609 mensajes CAN\n",
      " Procesado como red: CAN_CUSTOM_03F69071\n",
      "      Registros: 636,609 | Columnas: 6\n",
      "Procesando: Logging_2025-09-12_07-28-31.blf\n",
      "Leyendo BLF real: Logging_2025-09-12_07-28-31.blf\n",
      "      Procesados 50,000 mensajes...\n",
      "      Procesados 100,000 mensajes...\n",
      "      Procesados 150,000 mensajes...\n",
      "      Procesados 100,000 mensajes...\n",
      "      Procesados 150,000 mensajes...\n",
      "      Procesados 200,000 mensajes...\n",
      "      Procesados 250,000 mensajes...\n",
      "      Procesados 200,000 mensajes...\n",
      "      Procesados 250,000 mensajes...\n",
      "      Procesados 300,000 mensajes...\n",
      "      Procesados 350,000 mensajes...\n",
      "      Procesados 300,000 mensajes...\n",
      "      Procesados 350,000 mensajes...\n",
      "      Procesados 400,000 mensajes...\n",
      "      Procesados 400,000 mensajes...\n",
      "      Procesados 450,000 mensajes...\n",
      "      Procesados 450,000 mensajes...\n",
      "      Procesados 500,000 mensajes...\n",
      "      Procesados 550,000 mensajes...\n",
      "      Procesados 500,000 mensajes...\n",
      "      Procesados 550,000 mensajes...\n",
      "      Procesados 600,000 mensajes...\n",
      "      Procesados 600,000 mensajes...\n",
      "      Procesados 650,000 mensajes...\n",
      "      Procesados 650,000 mensajes...\n",
      "      Procesados 700,000 mensajes...\n",
      "      Procesados 700,000 mensajes...\n",
      "      Procesados 750,000 mensajes...\n",
      "      Procesados 750,000 mensajes...\n",
      "      Procesados 800,000 mensajes...\n",
      "      Procesados 800,000 mensajes...\n",
      "      Procesados 850,000 mensajes...\n",
      "      Procesados 850,000 mensajes...\n",
      "      Procesados 900,000 mensajes...\n",
      "      Procesados 900,000 mensajes...\n",
      "      Procesados 950,000 mensajes...\n",
      "      Procesados 950,000 mensajes...\n",
      "      Procesados 1,000,000 mensajes...\n",
      "      Procesados 1,000,000 mensajes...\n",
      "BLF real cargado: 1,028,096 mensajes CAN\n",
      " Procesado como red: CAN_CUSTOM_CF302D39\n",
      "      Registros: 1,028,096 | Columnas: 6\n",
      "Procesando: Logging_2025-09-12_07-43-57.blf\n",
      "Leyendo BLF real: Logging_2025-09-12_07-43-57.blf\n",
      "BLF real cargado: 1,028,096 mensajes CAN\n",
      " Procesado como red: CAN_CUSTOM_CF302D39\n",
      "      Registros: 1,028,096 | Columnas: 6\n",
      "Procesando: Logging_2025-09-12_07-43-57.blf\n",
      "Leyendo BLF real: Logging_2025-09-12_07-43-57.blf\n",
      "      Procesados 50,000 mensajes...\n",
      "      Procesados 50,000 mensajes...\n",
      "      Procesados 100,000 mensajes...\n",
      "      Procesados 150,000 mensajes...\n",
      "      Procesados 100,000 mensajes...\n",
      "      Procesados 150,000 mensajes...\n",
      "      Procesados 200,000 mensajes...\n",
      "      Procesados 200,000 mensajes...\n",
      "      Procesados 250,000 mensajes...\n",
      "      Procesados 250,000 mensajes...\n",
      "      Procesados 300,000 mensajes...\n",
      "      Procesados 300,000 mensajes...\n",
      "      Procesados 350,000 mensajes...\n",
      "      Procesados 400,000 mensajes...\n",
      "      Procesados 350,000 mensajes...\n",
      "      Procesados 400,000 mensajes...\n",
      "      Procesados 450,000 mensajes...\n",
      "      Procesados 500,000 mensajes...\n",
      "      Procesados 450,000 mensajes...\n",
      "      Procesados 500,000 mensajes...\n",
      "      Procesados 550,000 mensajes...\n",
      "      Procesados 600,000 mensajes...\n",
      "      Procesados 550,000 mensajes...\n",
      "      Procesados 600,000 mensajes...\n",
      "      Procesados 650,000 mensajes...\n",
      "      Procesados 700,000 mensajes...\n",
      "      Procesados 650,000 mensajes...\n",
      "      Procesados 700,000 mensajes...\n",
      "      Procesados 750,000 mensajes...\n",
      "      Procesados 750,000 mensajes...\n",
      "      Procesados 800,000 mensajes...\n",
      "      Procesados 800,000 mensajes...\n",
      "      Procesados 850,000 mensajes...\n",
      "      Procesados 900,000 mensajes...\n",
      "      Procesados 850,000 mensajes...\n",
      "      Procesados 900,000 mensajes...\n",
      "      Procesados 950,000 mensajes...\n",
      "      Procesados 1,000,000 mensajes...\n",
      "      Procesados 950,000 mensajes...\n",
      "      Procesados 1,000,000 mensajes...\n",
      "BLF real cargado: 1,000,124 mensajes CAN\n",
      " Procesado como red: CAN_CUSTOM_A4905C2D\n",
      "      Registros: 1,000,124 | Columnas: 6\n",
      "Procesando: Logging_2025-09-12_07-59-10.blf\n",
      "Leyendo BLF real: Logging_2025-09-12_07-59-10.blf\n",
      "BLF real cargado: 1,000,124 mensajes CAN\n",
      " Procesado como red: CAN_CUSTOM_A4905C2D\n",
      "      Registros: 1,000,124 | Columnas: 6\n",
      "Procesando: Logging_2025-09-12_07-59-10.blf\n",
      "Leyendo BLF real: Logging_2025-09-12_07-59-10.blf\n",
      "      Procesados 50,000 mensajes...\n",
      "      Procesados 100,000 mensajes...\n",
      "      Procesados 50,000 mensajes...\n",
      "      Procesados 100,000 mensajes...\n",
      "      Procesados 150,000 mensajes...\n",
      "      Procesados 200,000 mensajes...\n",
      "      Procesados 150,000 mensajes...\n",
      "      Procesados 200,000 mensajes...\n",
      "      Procesados 250,000 mensajes...\n",
      "      Procesados 300,000 mensajes...\n",
      "      Procesados 250,000 mensajes...\n",
      "      Procesados 300,000 mensajes...\n",
      "      Procesados 350,000 mensajes...\n",
      "      Procesados 350,000 mensajes...\n",
      "      Procesados 400,000 mensajes...\n",
      "      Procesados 450,000 mensajes...\n",
      "      Procesados 400,000 mensajes...\n",
      "      Procesados 450,000 mensajes...\n",
      "      Procesados 500,000 mensajes...\n",
      "      Procesados 500,000 mensajes...\n",
      "      Procesados 550,000 mensajes...\n",
      "      Procesados 600,000 mensajes...\n",
      "      Procesados 550,000 mensajes...\n",
      "      Procesados 600,000 mensajes...\n",
      "      Procesados 650,000 mensajes...\n",
      "      Procesados 700,000 mensajes...\n",
      "      Procesados 650,000 mensajes...\n",
      "      Procesados 700,000 mensajes...\n",
      "      Procesados 750,000 mensajes...\n",
      "      Procesados 800,000 mensajes...\n",
      "      Procesados 750,000 mensajes...\n",
      "      Procesados 800,000 mensajes...\n",
      "      Procesados 850,000 mensajes...\n",
      "      Procesados 850,000 mensajes...\n",
      "      Procesados 900,000 mensajes...\n",
      "      Procesados 950,000 mensajes...\n",
      "      Procesados 900,000 mensajes...\n",
      "      Procesados 950,000 mensajes...\n",
      "      Procesados 1,000,000 mensajes...\n",
      "      Procesados 1,000,000 mensajes...\n",
      "      Procesados 1,050,000 mensajes...\n",
      "      Procesados 1,100,000 mensajes...\n",
      "      Procesados 1,050,000 mensajes...\n",
      "      Procesados 1,100,000 mensajes...\n",
      "      Procesados 1,150,000 mensajes...\n",
      "      Procesados 1,200,000 mensajes...\n",
      "      Procesados 1,150,000 mensajes...\n",
      "      Procesados 1,200,000 mensajes...\n",
      "      Procesados 1,250,000 mensajes...\n",
      "      Procesados 1,300,000 mensajes...\n",
      "      Procesados 1,250,000 mensajes...\n",
      "      Procesados 1,300,000 mensajes...\n",
      "      Procesados 1,350,000 mensajes...\n",
      "      Procesados 1,350,000 mensajes...\n",
      "BLF real cargado: 1,375,854 mensajes CAN\n",
      "BLF real cargado: 1,375,854 mensajes CAN\n",
      " Procesado como red: CAN_CUSTOM_CF0AB8E5\n",
      "      Registros: 1,375,854 | Columnas: 6\n",
      "Procesando: Logging_2025-09-12_08-19-48.blf\n",
      "Leyendo BLF real: Logging_2025-09-12_08-19-48.blf\n",
      " Procesado como red: CAN_CUSTOM_CF0AB8E5\n",
      "      Registros: 1,375,854 | Columnas: 6\n",
      "Procesando: Logging_2025-09-12_08-19-48.blf\n",
      "Leyendo BLF real: Logging_2025-09-12_08-19-48.blf\n",
      "      Procesados 50,000 mensajes...\n",
      "      Procesados 50,000 mensajes...\n",
      "      Procesados 100,000 mensajes...\n",
      "      Procesados 100,000 mensajes...\n",
      "      Procesados 150,000 mensajes...\n",
      "      Procesados 150,000 mensajes...\n",
      "      Procesados 200,000 mensajes...\n",
      "      Procesados 200,000 mensajes...\n",
      "      Procesados 250,000 mensajes...\n",
      "      Procesados 250,000 mensajes...\n",
      "      Procesados 300,000 mensajes...\n",
      "      Procesados 300,000 mensajes...\n",
      "      Procesados 350,000 mensajes...\n",
      "      Procesados 350,000 mensajes...\n",
      "      Procesados 400,000 mensajes...\n",
      "      Procesados 400,000 mensajes...\n",
      "      Procesados 450,000 mensajes...\n",
      "      Procesados 450,000 mensajes...\n",
      "      Procesados 500,000 mensajes...\n",
      "      Procesados 500,000 mensajes...\n",
      "      Procesados 550,000 mensajes...\n",
      "      Procesados 550,000 mensajes...\n",
      "      Procesados 600,000 mensajes...\n",
      "      Procesados 600,000 mensajes...\n",
      "      Procesados 650,000 mensajes...\n",
      "      Procesados 700,000 mensajes...\n",
      "      Procesados 650,000 mensajes...\n",
      "      Procesados 700,000 mensajes...\n",
      "      Procesados 750,000 mensajes...\n",
      "      Procesados 800,000 mensajes...\n",
      "      Procesados 750,000 mensajes...\n",
      "      Procesados 800,000 mensajes...\n",
      "      Procesados 850,000 mensajes...\n",
      "      Procesados 900,000 mensajes...\n",
      "      Procesados 850,000 mensajes...\n",
      "      Procesados 900,000 mensajes...\n",
      "      Procesados 950,000 mensajes...\n",
      "      Procesados 1,000,000 mensajes...\n",
      "      Procesados 950,000 mensajes...\n",
      "      Procesados 1,000,000 mensajes...\n",
      "      Procesados 1,050,000 mensajes...\n",
      "      Procesados 1,100,000 mensajes...\n",
      "      Procesados 1,050,000 mensajes...\n",
      "      Procesados 1,100,000 mensajes...\n",
      "      Procesados 1,150,000 mensajes...\n",
      "      Procesados 1,200,000 mensajes...\n",
      "      Procesados 1,150,000 mensajes...\n",
      "      Procesados 1,200,000 mensajes...\n",
      "      Procesados 1,250,000 mensajes...\n",
      "      Procesados 1,300,000 mensajes...\n",
      "      Procesados 1,250,000 mensajes...\n",
      "      Procesados 1,300,000 mensajes...\n",
      "      Procesados 1,350,000 mensajes...\n",
      "      Procesados 1,350,000 mensajes...\n",
      "BLF real cargado: 1,396,893 mensajes CAN\n",
      " Procesado como red: CAN_CUSTOM_60E31DA1\n",
      "      Registros: 1,396,893 | Columnas: 6\n",
      "\n",
      " RESUMEN DATOS:\n",
      "   Archivos procesados: 5\n",
      "   Redes CAN identificadas: 5\n",
      "   Total registros cargados: 5,437,576\n",
      "CAN_CUSTOM_03F69071:\n",
      "      Registros: 636,609\n",
      "      Columnas: 6\n",
      "      Período: 2025-09-12 07:17:31.703922749 a 2025-09-12 07:27:07.690173149\n",
      "CAN_CUSTOM_CF302D39:\n",
      "      Registros: 1,028,096\n",
      "      Columnas: 6\n",
      "      Período: 2025-09-12 07:28:31.471541643 a 2025-09-12 07:43:53.680799007\n",
      "CAN_CUSTOM_A4905C2D:\n",
      "      Registros: 1,000,124\n",
      "      Columnas: 6\n",
      "      Período: 2025-09-12 07:43:57.586159229 a 2025-09-12 07:59:02.962466240\n",
      "CAN_CUSTOM_CF0AB8E5:\n",
      "      Registros: 1,375,854\n",
      "      Columnas: 6\n",
      "      Período: 2025-09-12 07:59:10.094649792 a 2025-09-12 08:19:44.271649599\n",
      "CAN_CUSTOM_60E31DA1:\n",
      "      Registros: 1,396,893\n",
      "      Columnas: 6\n",
      "      Período: 2025-09-12 08:19:48.069771290 a 2025-09-12 08:40:47.527005195\n",
      "\n",
      " VALIDACIÓN DE INTEGRIDAD DE DATOS\n",
      "Validando CAN_CUSTOM_03F69071...\n",
      "BLF real cargado: 1,396,893 mensajes CAN\n",
      " Procesado como red: CAN_CUSTOM_60E31DA1\n",
      "      Registros: 1,396,893 | Columnas: 6\n",
      "\n",
      " RESUMEN DATOS:\n",
      "   Archivos procesados: 5\n",
      "   Redes CAN identificadas: 5\n",
      "   Total registros cargados: 5,437,576\n",
      "CAN_CUSTOM_03F69071:\n",
      "      Registros: 636,609\n",
      "      Columnas: 6\n",
      "      Período: 2025-09-12 07:17:31.703922749 a 2025-09-12 07:27:07.690173149\n",
      "CAN_CUSTOM_CF302D39:\n",
      "      Registros: 1,028,096\n",
      "      Columnas: 6\n",
      "      Período: 2025-09-12 07:28:31.471541643 a 2025-09-12 07:43:53.680799007\n",
      "CAN_CUSTOM_A4905C2D:\n",
      "      Registros: 1,000,124\n",
      "      Columnas: 6\n",
      "      Período: 2025-09-12 07:43:57.586159229 a 2025-09-12 07:59:02.962466240\n",
      "CAN_CUSTOM_CF0AB8E5:\n",
      "      Registros: 1,375,854\n",
      "      Columnas: 6\n",
      "      Período: 2025-09-12 07:59:10.094649792 a 2025-09-12 08:19:44.271649599\n",
      "CAN_CUSTOM_60E31DA1:\n",
      "      Registros: 1,396,893\n",
      "      Columnas: 6\n",
      "      Período: 2025-09-12 08:19:48.069771290 a 2025-09-12 08:40:47.527005195\n",
      "\n",
      " VALIDACIÓN DE INTEGRIDAD DE DATOS\n",
      "Validando CAN_CUSTOM_03F69071...\n",
      "   ✅ CAN_CUSTOM_03F69071: 636,609 registros válidos\n",
      "Validando CAN_CUSTOM_CF302D39...\n",
      "   ✅ CAN_CUSTOM_CF302D39: 1,028,096 registros válidos\n",
      "Validando CAN_CUSTOM_A4905C2D...\n",
      "   ✅ CAN_CUSTOM_A4905C2D: 1,000,124 registros válidos\n",
      "Validando CAN_CUSTOM_CF0AB8E5...\n",
      "   ✅ CAN_CUSTOM_03F69071: 636,609 registros válidos\n",
      "Validando CAN_CUSTOM_CF302D39...\n",
      "   ✅ CAN_CUSTOM_CF302D39: 1,028,096 registros válidos\n",
      "Validando CAN_CUSTOM_A4905C2D...\n",
      "   ✅ CAN_CUSTOM_A4905C2D: 1,000,124 registros válidos\n",
      "Validando CAN_CUSTOM_CF0AB8E5...\n",
      "   ✅ CAN_CUSTOM_CF0AB8E5: 1,375,854 registros válidos\n",
      "Validando CAN_CUSTOM_60E31DA1...\n",
      "   ✅ CAN_CUSTOM_60E31DA1: 1,396,893 registros válidos\n",
      "TODOS LOS DATASETS VALIDADOS CORRECTAMENTE\n",
      "\n",
      " CONFIGURACIÓN COMPLETADA\n",
      "==================================================\n",
      "ESTADO FINAL DEL SISTEMA:\n",
      "   Definiciones DBC: 2 archivos procesados\n",
      "   Datos vehiculares: 5 redes CAN cargadas\n",
      "   Total registros: 5,437,576\n",
      "   Origen de datos: 100% REAL (sin simulaciones)\n",
      "\n",
      " REDES CAN DISPONIBLES PARA ANÁLISIS:\n",
      "   📡 CAN_CUSTOM_03F69071: 636,609 registros | 6 columnas\n",
      "   📡 CAN_CUSTOM_60E31DA1: 1,396,893 registros | 6 columnas\n",
      "   📡 CAN_CUSTOM_A4905C2D: 1,000,124 registros | 6 columnas\n",
      "   📡 CAN_CUSTOM_CF0AB8E5: 1,375,854 registros | 6 columnas\n",
      "   📡 CAN_CUSTOM_CF302D39: 1,028,096 registros | 6 columnas\n",
      "\n",
      " SISTEMA LISTO PARA ANÁLISIS AVANZADO\n",
      "   Los datos están disponibles en la variable 'datos_can'\n",
      "   Las definiciones están en 'definiciones_dbc'\n",
      "\n",
      " EJEMPLO DE DATOS CARGADOS:\n",
      "\n",
      "CAN_CUSTOM_03F69071 (primeras 3 filas):\n",
      "                      timestamp arbitration_id              data  dlc  is_extended  channel\n",
      "0 2025-09-12 07:17:31.703922749      0xCF00203  c4ffffff3f0000ff    8         True        0\n",
      "1 2025-09-12 07:17:31.704487085      0xCF0045A  fe7d7d0000ff0fff    8         True        0\n",
      "2 2025-09-12 07:17:31.705063105     0x18FF20EF  0e7d0000ffffff7d    8         True        0\n",
      "\n",
      "CAN_CUSTOM_CF302D39 (primeras 3 filas):\n",
      "                      timestamp arbitration_id              data  dlc  is_extended  channel\n",
      "0 2025-09-12 07:28:31.471541643      0xCFF3F27  11f0ffff00210003    8         True        0\n",
      "1 2025-09-12 07:28:31.472721815      0xCEFEF0B  acfa3affffffff60    8         True        0\n",
      "2 2025-09-12 07:28:31.473721981      0xCFF80EF  7d7f7de119000057    8         True        0\n",
      "   ✅ CAN_CUSTOM_CF0AB8E5: 1,375,854 registros válidos\n",
      "Validando CAN_CUSTOM_60E31DA1...\n",
      "   ✅ CAN_CUSTOM_60E31DA1: 1,396,893 registros válidos\n",
      "TODOS LOS DATASETS VALIDADOS CORRECTAMENTE\n",
      "\n",
      " CONFIGURACIÓN COMPLETADA\n",
      "==================================================\n",
      "ESTADO FINAL DEL SISTEMA:\n",
      "   Definiciones DBC: 2 archivos procesados\n",
      "   Datos vehiculares: 5 redes CAN cargadas\n",
      "   Total registros: 5,437,576\n",
      "   Origen de datos: 100% REAL (sin simulaciones)\n",
      "\n",
      " REDES CAN DISPONIBLES PARA ANÁLISIS:\n",
      "   📡 CAN_CUSTOM_03F69071: 636,609 registros | 6 columnas\n",
      "   📡 CAN_CUSTOM_60E31DA1: 1,396,893 registros | 6 columnas\n",
      "   📡 CAN_CUSTOM_A4905C2D: 1,000,124 registros | 6 columnas\n",
      "   📡 CAN_CUSTOM_CF0AB8E5: 1,375,854 registros | 6 columnas\n",
      "   📡 CAN_CUSTOM_CF302D39: 1,028,096 registros | 6 columnas\n",
      "\n",
      " SISTEMA LISTO PARA ANÁLISIS AVANZADO\n",
      "   Los datos están disponibles en la variable 'datos_can'\n",
      "   Las definiciones están en 'definiciones_dbc'\n",
      "\n",
      " EJEMPLO DE DATOS CARGADOS:\n",
      "\n",
      "CAN_CUSTOM_03F69071 (primeras 3 filas):\n",
      "                      timestamp arbitration_id              data  dlc  is_extended  channel\n",
      "0 2025-09-12 07:17:31.703922749      0xCF00203  c4ffffff3f0000ff    8         True        0\n",
      "1 2025-09-12 07:17:31.704487085      0xCF0045A  fe7d7d0000ff0fff    8         True        0\n",
      "2 2025-09-12 07:17:31.705063105     0x18FF20EF  0e7d0000ffffff7d    8         True        0\n",
      "\n",
      "CAN_CUSTOM_CF302D39 (primeras 3 filas):\n",
      "                      timestamp arbitration_id              data  dlc  is_extended  channel\n",
      "0 2025-09-12 07:28:31.471541643      0xCFF3F27  11f0ffff00210003    8         True        0\n",
      "1 2025-09-12 07:28:31.472721815      0xCEFEF0B  acfa3affffffff60    8         True        0\n",
      "2 2025-09-12 07:28:31.473721981      0xCFF80EF  7d7f7de119000057    8         True        0\n"
     ]
    }
   ],
   "source": [
    "# === PROCESAMIENTO DE DATOS VEHICULARES REALES ===\n",
    "\n",
    "print(\"SISTEMA DE PROCESAMIENTO CAN - DATOS REALES ÚNICAMENTE\")\n",
    "print(\"=\" * 65)\n",
    "print(\"CONFIGURACIÓN:\")\n",
    "print(\"- Solo datos reales del vehículo\")\n",
    "print(\"- Archivos DBC y BLF auténticos\")  \n",
    "print(\"- Sin simulaciones ni datos sintéticos\")\n",
    "print(\"- Procesamiento directo desde operación vehicular\\n\")\n",
    "\n",
    "# === PASO 1: CARGAR ARCHIVOS DBC REALES ===\n",
    "try:\n",
    "    print(\"CARGA DE DEFINICIONES DBC REALES\")\n",
    "    archivos_dbc = seleccionar_archivos_dbc()\n",
    "    \n",
    "    print(\"Procesando archivos DBC seleccionados...\")\n",
    "    definiciones_dbc = procesar_archivos_dbc_solo_reales(archivos_dbc)\n",
    "    \n",
    "    # Resumen de definiciones cargadas\n",
    "    total_senales = sum(len(def_dbc['señales']) for def_dbc in definiciones_dbc.values() if def_dbc['procesado'])\n",
    "    print(f\"\\nRESUMEN DBC:\")\n",
    "    print(f\"   Archivos procesados: {len(definiciones_dbc)}\")\n",
    "    print(f\"   Total señales definidas: {total_senales}\")\n",
    "    \n",
    "    for nombre_archivo, definicion in definiciones_dbc.items():\n",
    "        if definicion['procesado']:\n",
    "            print(f\"{nombre_archivo}: {len(definicion['señales'])} señales\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  ERROR CRÍTICO en carga DBC: {e}\")\n",
    "    print(\"   El procesamiento no puede continuar sin definiciones DBC\")\n",
    "    raise\n",
    "\n",
    "# === PASO 2: CARGAR ARCHIVOS DE DATOS REALES ===\n",
    "try:\n",
    "    print(f\"\\n CARGA DE DATOS VEHICULARES REALES\")\n",
    "    archivos_datos = seleccionar_archivos_blf()\n",
    "    \n",
    "    print(\" Procesando archivos de datos seleccionados...\")\n",
    "    datos_can = cargar_datos_solo_reales(archivos_datos, definiciones_dbc)\n",
    "    \n",
    "    # Resumen de datos cargados\n",
    "    total_registros = sum(len(df) for df in datos_can.values())\n",
    "    print(f\"\\n RESUMEN DATOS:\")\n",
    "    print(f\"   Archivos procesados: {len(archivos_datos)}\")\n",
    "    print(f\"   Redes CAN identificadas: {len(datos_can)}\")\n",
    "    print(f\"   Total registros cargados: {total_registros:,}\")\n",
    "    \n",
    "    for red_can, df in datos_can.items():\n",
    "        print(f\"{red_can}:\")\n",
    "        print(f\"      Registros: {len(df):,}\")\n",
    "        print(f\"      Columnas: {len(df.columns)}\")\n",
    "        if len(df) > 0:\n",
    "            tiempo_inicial = df['timestamp'].min() if 'timestamp' in df.columns else 'N/A'\n",
    "            tiempo_final = df['timestamp'].max() if 'timestamp' in df.columns else 'N/A'\n",
    "            if tiempo_inicial != 'N/A':\n",
    "                print(f\"      Período: {tiempo_inicial} a {tiempo_final}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR CRÍTICO en carga de datos: {e}\")\n",
    "    print(\"   El procesamiento no puede continuar sin datos del vehículo\")\n",
    "    raise\n",
    "\n",
    "# === PASO 3: VALIDACIÓN DE DATOS CARGADOS ===\n",
    "print(f\"\\n VALIDACIÓN DE INTEGRIDAD DE DATOS\")\n",
    "datos_validos = True\n",
    "\n",
    "for red_can, df in datos_can.items():\n",
    "    print(f\"Validando {red_can}...\")\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        print(f\"Sin datos en {red_can}\")\n",
    "        datos_validos = False\n",
    "        continue\n",
    "    \n",
    "    # Verificar columnas esenciales\n",
    "    columnas_esperadas = ['timestamp'] if 'timestamp' in df.columns else []\n",
    "    columnas_faltantes = [col for col in columnas_esperadas if col not in df.columns]\n",
    "    \n",
    "    if columnas_faltantes:\n",
    "        print(f\" Columnas faltantes en {red_can}: {columnas_faltantes}\")\n",
    "    \n",
    "    # Verificar datos nulos\n",
    "    nulos_por_columna = df.isnull().sum()\n",
    "    columnas_con_nulos = nulos_por_columna[nulos_por_columna > 0]\n",
    "    \n",
    "    if len(columnas_con_nulos) > 0:\n",
    "        print(f\" Columnas con valores nulos en {red_can}: {len(columnas_con_nulos)}\")\n",
    "    \n",
    "    print(f\"   ✅ {red_can}: {len(df):,} registros válidos\")\n",
    "\n",
    "if not datos_validos:\n",
    "    print(\"ADVERTENCIA: Algunos datasets tienen problemas de integridad\")\n",
    "else:\n",
    "    print(\"TODOS LOS DATASETS VALIDADOS CORRECTAMENTE\")\n",
    "\n",
    "# === PASO 4: CONFIGURACIÓN FINAL ===\n",
    "print(f\"\\n CONFIGURACIÓN COMPLETADA\")\n",
    "print(\"=\" * 50)\n",
    "print(\"ESTADO FINAL DEL SISTEMA:\")\n",
    "print(f\"   Definiciones DBC: {len(definiciones_dbc)} archivos procesados\")\n",
    "print(f\"   Datos vehiculares: {len(datos_can)} redes CAN cargadas\")\n",
    "print(f\"   Total registros: {sum(len(df) for df in datos_can.values()):,}\")\n",
    "print(f\"   Origen de datos: 100% REAL (sin simulaciones)\")\n",
    "\n",
    "print(f\"\\n REDES CAN DISPONIBLES PARA ANÁLISIS:\")\n",
    "for red_can in sorted(datos_can.keys()):\n",
    "    df = datos_can[red_can]\n",
    "    print(f\"   📡 {red_can}: {len(df):,} registros | {len(df.columns)} columnas\")\n",
    "\n",
    "print(f\"\\n SISTEMA LISTO PARA ANÁLISIS AVANZADO\")\n",
    "print(\"   Los datos están disponibles en la variable 'datos_can'\")\n",
    "print(\"   Las definiciones están en 'definiciones_dbc'\")\n",
    "\n",
    "# Mostrar ejemplo de los primeros registros\n",
    "print(f\"\\n EJEMPLO DE DATOS CARGADOS:\")\n",
    "for red_can, df in list(datos_can.items())[:2]:  # Solo primeras 2 redes\n",
    "    print(f\"\\n{red_can} (primeras 3 filas):\")\n",
    "    if len(df) > 0:\n",
    "        print(df.head(3).to_string(max_cols=6))\n",
    "    else:\n",
    "        print(\"   Sin datos disponibles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f990a0d6",
   "metadata": {},
   "source": [
    "## 3. Motor de Transformación Semántica: De Señales CAN a Narrativas Descriptivas\n",
    "\n",
    "### Arquitectura del Sistema de Transformación Semántica\n",
    "\n",
    "El sistema implementa una **arquitectura multi-capa** que procesa datos CAN en múltiples niveles de abstracción:\n",
    "\n",
    "1. **Capa de Análisis Temporal:** Identificación de patrones estadísticos en series temporales\n",
    "2. **Capa de Contextualización:** Enriquecimiento con metadatos operacionales vehiculares  \n",
    "3. **Capa de Generación Textual:** Aplicación de plantillas semánticas dominio-específicas\n",
    "4. **Capa de Validación Semántica:** Verificación de coherencia y precisión técnica\n",
    "\n",
    "### Estrategia de Implementación: Plantillas Adaptativas\n",
    "\n",
    "La generación textual utiliza un sistema de **plantillas adaptativas** que se especializan según:\n",
    "\n",
    "- **Tipo de patrón temporal:** Incremental, decremental, cíclico, anómalo\n",
    "- **Red CAN específica:** CAN_EV, CAN_CATL, CAN_CARROC, AUX_CHG  \n",
    "- **Contexto operacional:** Normal, transitorio, crítico, mantenimiento\n",
    "- **Audiencia objetivo:** Técnico especializado vs. conversacional general\n",
    "\n",
    "### Innovación Metodológica: Preservación de Precisión Técnica\n",
    "\n",
    "A diferencia de sistemas de generación genéricos, la implementación desarrollada incorpora mecanismos específicos para preservar información técnica crítica:\n",
    "\n",
    "- **Unidades de medida:** Preservación exacta con expansión semántica\n",
    "- **Rangos operacionales:** Contextualización de valores respecto a umbrales normales\n",
    "- **Relaciones causales:** Identificación de correlaciones inter-señales  \n",
    "- **Trazabilidad temporal:** Referencia precisa a marcas temporales BLF\n",
    "\n",
    "\n",
    "El motor de transformación semántica ejecuta el siguiente proceso para hacer la conversión de CAN a texto \n",
    "\n",
    "![Descripción de la imagen](https://raw.githubusercontent.com/A01794020Henry/Proyecto_Integrador_Grupo7_IBM/main/Entrega2_Ingenieria_de_requisitos/Generaci%C3%B3n%20de%20desccripciones%20-%20Conversi%C3%B3n%20CAN%20a%20Texto.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d7c18a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneradorDescripcionesTextual:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Inicializa el motor con plantillas especializadas y configuraciones por red CAN.\n",
    "        \"\"\"\n",
    "        # Sistema de plantillas adaptativas para patrones temporales identificados\n",
    "        # Cada plantilla preserva información técnica crítica con variaciones semánticas\n",
    "        self.plantillas_temporal = {\n",
    "            'incremento_sostenido': [\n",
    "                \"En el período de análisis temporal, la señal {signal} exhibió un incremento sostenido progresivo desde {valor_inicial:.2f} hasta {valor_final:.2f} {unidad}, registrado en logs BLF entre {tiempo_inicio} y {tiempo_fin} con una tasa de cambio promedio de {tasa_cambio:.3f} {unidad}/minuto.\",\n",
    "                \n",
    "                \"Los datos BLF revelan un comportamiento de crecimiento controlado en {signal}: incremento total de {cambio_total:.2f} {unidad} durante {duracion_min:.1f} minutos de operación, manteniendo estabilidad con desviación estándar de {desviacion:.3f} {unidad}.\",\n",
    "                \n",
    "                \"Análisis temporal detallado: {signal} mantuvo una tendencia ascendente consistente con incremento porcentual de {cambio_porcentual:.1f}%, sin eventos anómalos significativos durante la ventana de observación ({duracion_min:.1f} min).\"\n",
    "            ],\n",
    "            \n",
    "            'decremento_sostenido': [\n",
    "                \"Durante la ventana temporal analizada, {signal} ejecutó una reducción controlada desde {valor_inicial:.2f} hasta {valor_final:.2f} {unidad}, documentada en logs BLF con tasa de decremento de {tasa_cambio:.3f} {unidad}/minuto.\",\n",
    "                \n",
    "                \"Los registros temporales evidencian un patrón de descenso gradual en {signal}: reducción total de {cambio_total:.2f} {unidad} ({cambio_porcentual:.1f}%) manteniendo comportamiento estable durante {duracion_min:.1f} minutos.\",\n",
    "                \n",
    "                \"Comportamiento de decremento controlado detectado: {signal} redujo sistemáticamente su valor operacional con desviación contenida (σ={desviacion:.3f}) según análisis estadístico de logs vehiculares.\"\n",
    "            ],\n",
    "            \n",
    "            'estabilidad': [\n",
    "                \"Los datos BLF confirman estabilidad operacional excepcional en {signal}: valor promedio de {valor_promedio:.2f} {unidad} con desviación estándar mínima (σ={desviacion:.3f}) durante {duracion_min:.1f} minutos de monitoreo continuo.\",\n",
    "                \n",
    "                \"Comportamiento operacional estable registrado: {signal} mantuvo oscilaciones contenidas dentro del rango [{valor_min:.2f}, {valor_max:.2f}] {unidad}, indicando funcionamiento nominal del sistema según logs temporales.\",\n",
    "                \n",
    "                \"Análisis de estabilidad crítica: {signal} exhibió variación controlada de ±{rango_variacion:.2f} {unidad} (CV={coef_variacion:.2f}%) respecto al valor nominal, confirmando operación dentro de parámetros de diseño.\"\n",
    "            ],\n",
    "            \n",
    "            'picos_anomalos': [\n",
    "                \"Los logs BLF identifican {num_picos} eventos de comportamiento anómalo en {signal}: valores extremos registrados entre {valor_min:.2f} y {valor_max:.2f} {unidad}, excediendo umbrales operacionales normales (μ±2σ).\",\n",
    "                \n",
    "                \"Detección avanzada de anomalías temporales: {signal} presentó {num_picos} episodios fuera de comportamiento estadísticamente normal durante {duracion_min:.1f} minutos, requiriendo análisis de causas raíz.\",\n",
    "                \n",
    "                \"Eventos excepcionales críticos identificados: {signal} registró {num_picos} ocurrencias con desviaciones >2σ del comportamiento esperado, sugiriendo condiciones operacionales no nominales o transitorios del sistema.\"\n",
    "            ],\n",
    "            \n",
    "            'patron_ciclico': [\n",
    "                \"Análisis espectral de logs BLF revela comportamiento cíclico significativo en {signal}: período dominante de {periodo_min:.1f} minutos con amplitud característica de {amplitud:.2f} {unidad} y regularidad del {regularidad:.1f}%.\",\n",
    "                \n",
    "                \"Comportamiento periódico detectado mediante FFT: {signal} exhibe oscilaciones sistemáticas con frecuencia fundamental de {frecuencia:.3f} Hz durante operación normal, consistente con ciclos operacionales del sistema.\",\n",
    "                \n",
    "                \"Patrón temporal cíclico confirmado: {signal} mantiene periodicidad estable cada {periodo_min:.1f} minutos con coeficiente de determinación R²={r_cuadrado:.3f}, indicando comportamiento predecible del subsistema.\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Configuraciones especializadas por red CAN con contexto técnico específico\n",
    "        self.plantillas_por_red = {\n",
    "            'CAN_EV': {  # Red de propulsión eléctrica - Máxima criticidad\n",
    "                'contexto': \"Durante la operación del sistema de propulsión eléctrica principal\",\n",
    "                'enfoque': \"motor de tracción, inversor de potencia y control vectorial\",\n",
    "                'unidades_comunes': {\n",
    "                    'RPM': 'revoluciones por minuto', 'Nm': 'newton-metros de torque', \n",
    "                    'A': 'amperios de corriente', 'V': 'voltios DC', 'C': 'grados Celsius',\n",
    "                    'Hz': 'hertz de frecuencia', 'W': 'watts de potencia'\n",
    "                },\n",
    "                'criticidad': 'alta',\n",
    "                'contexto_operacional': 'tracción vehicular'\n",
    "            },\n",
    "            \n",
    "            'CAN_CATL': {  # Sistema de batería - Datos propietarios no documentados\n",
    "                'contexto': \"En el sistema de gestión de batería CATL (protocolo propietario sin documentación DBC)\",\n",
    "                'enfoque': \"gestión térmica, balanceado de celdas y estado de carga inferido\",\n",
    "                'unidades_comunes': {\n",
    "                    'V': 'voltios de celda/pack', '%': 'porcentaje SOC/SOH', \n",
    "                    'C': 'grados Celsius', 'A': 'amperios de carga/descarga',\n",
    "                    'Ah': 'amperios-hora', 'Wh': 'watts-hora'\n",
    "                },\n",
    "                'criticidad': 'crítica',\n",
    "                'contexto_operacional': 'almacenamiento energético'\n",
    "            },\n",
    "            \n",
    "            'CAN_CARROC': {  # Sistemas de carrocería - Baja criticidad operacional\n",
    "                'contexto': \"En los subsistemas de carrocería, confort y auxiliares del vehículo\",\n",
    "                'enfoque': \"control de accesos, climatización y sistemas de confort pasajero\",\n",
    "                'unidades_comunes': {\n",
    "                    'bool': 'estado binario (abierto/cerrado)', 'C': 'grados Celsius',\n",
    "                    '%': 'porcentaje de ajuste', 'lux': 'unidades de iluminación'\n",
    "                },\n",
    "                'criticidad': 'baja',\n",
    "                'contexto_operacional': 'confort y accesibilidad'\n",
    "            },\n",
    "            \n",
    "            'AUX_CHG': {  # Sistema de carga auxiliar - Criticidad media\n",
    "                'contexto': \"Durante los procesos de carga auxiliar y gestión energética secundaria\",\n",
    "                'enfoque': \"cargador AC/DC, gestión de carga bidireccional y sistemas auxiliares\",\n",
    "                'unidades_comunes': {\n",
    "                    'V': 'voltios AC/DC', 'A': 'amperios de carga', \n",
    "                    'C': 'grados Celsius', 'W': 'watts de potencia',\n",
    "                    'kWh': 'kilowatts-hora', '%': 'porcentaje de eficiencia'\n",
    "                },\n",
    "                'criticidad': 'media',\n",
    "                'contexto_operacional': 'recarga energética'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Métricas de calidad para validación semántica automatizada\n",
    "        self.metricas_calidad = {\n",
    "            'precision_numerica': 0.0,      # Preservación de valores numéricos exactos\n",
    "            'coherencia_unidades': 0.0,     # Consistencia en unidades de medida\n",
    "            'contextualización': 0.0,       # Relevancia del contexto operacional\n",
    "            'legibilidad_tecnica': 0.0,     # Balance técnico/conversacional\n",
    "            'completitud_informativa': 0.0  # Información técnica preservada\n",
    "        }\n",
    "    \n",
    "    def analizar_serie_temporal_blf(self, serie: pd.Series, timestamps: pd.Series) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Ejecuta análisis estadístico avanzado de series temporales BLF para identificación de patrones.\n",
    "        \n",
    "        Implementa análisis multi-dimensional que combina estadística descriptiva,\n",
    "        análisis espectral y detección de anomalías para clasificación automatizada de comportamientos.\n",
    "        \n",
    "        Args:\n",
    "            serie: Serie temporal de valores numéricos CAN\n",
    "            timestamps: Marcas temporales correspondientes (formato ISO 8601)\n",
    "            \n",
    "        Returns:\n",
    "            Diccionario con análisis completo: patrón, métricas estadísticas y metadatos temporales\n",
    "        \"\"\"\n",
    "        # Validación y limpieza de datos con logging detallado\n",
    "        datos_limpios = serie.dropna()\n",
    "        if len(datos_limpios) < 2:\n",
    "            logger.warning(f\"Datos insuficientes para análisis: {len(datos_limpios)} puntos válidos\")\n",
    "            return {\n",
    "                'tipo': 'datos_insuficientes', \n",
    "                'descripcion': 'Serie temporal con datos insuficientes para análisis estadístico',\n",
    "                'puntos_validos': len(datos_limpios)\n",
    "            }\n",
    "        \n",
    "        # Cálculo de métricas estadísticas fundamentales\n",
    "        valor_inicial = float(datos_limpios.iloc[0])\n",
    "        valor_final = float(datos_limpios.iloc[-1])\n",
    "        valor_promedio = float(datos_limpios.mean())\n",
    "        desviacion = float(datos_limpios.std()) if len(datos_limpios) > 1 else 0.0\n",
    "        valor_min = float(datos_limpios.min())\n",
    "        valor_max = float(datos_limpios.max())\n",
    "        mediana = float(datos_limpios.median())\n",
    "        \n",
    "        # Análisis temporal y cálculo de tasas de cambio\n",
    "        try:\n",
    "            tiempo_inicio = str(timestamps.iloc[0]) if len(timestamps) > 0 else \"timestamp_inicial\"\n",
    "            tiempo_fin = str(timestamps.iloc[-1]) if len(timestamps) > 0 else \"timestamp_final\"\n",
    "            duracion_min = float(len(datos_limpios) / 60) if len(timestamps) == len(datos_limpios) else float(len(datos_limpios))\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error procesando timestamps: {e}\")\n",
    "            tiempo_inicio, tiempo_fin, duracion_min = \"inicio\", \"fin\", float(len(datos_limpios))\n",
    "        \n",
    "        # Análisis de tendencias y cambios\n",
    "        cambio_total = valor_final - valor_inicial\n",
    "        cambio_porcentual = (cambio_total / valor_inicial * 100) if valor_inicial != 0 else 0.0\n",
    "        tasa_cambio = cambio_total / duracion_min if duracion_min > 0 else 0.0\n",
    "        \n",
    "        # Métricas avanzadas de variabilidad\n",
    "        rango_variacion = (valor_max - valor_min) / 2 if valor_max != valor_min else 0.0\n",
    "        coef_variacion = (desviacion / valor_promedio * 100) if valor_promedio != 0 else 0.0\n",
    "        \n",
    "        # Clasificación inteligente de patrones temporales\n",
    "        patron_identificado = self._clasificar_patron_temporal(\n",
    "            cambio_porcentual, coef_variacion, datos_limpios, valor_promedio, desviacion\n",
    "        )\n",
    "        \n",
    "        # Análisis de periodicidad (simplified FFT analysis)\n",
    "        periodo_min, frecuencia, amplitud, regularidad, r_cuadrado = self._analizar_periodicidad(datos_limpios)\n",
    "        \n",
    "        # Compilación de resultados con metadatos completos\n",
    "        resultado_analisis = {\n",
    "            'tipo': patron_identificado,\n",
    "            'valor_inicial': valor_inicial,\n",
    "            'valor_final': valor_final,\n",
    "            'valor_promedio': valor_promedio,\n",
    "            'desviacion': desviacion,\n",
    "            'valor_min': valor_min,\n",
    "            'valor_max': valor_max,\n",
    "            'mediana': mediana,\n",
    "            'tiempo_inicio': tiempo_inicio,\n",
    "            'tiempo_fin': tiempo_fin,\n",
    "            'duracion_min': duracion_min,\n",
    "            'cambio_total': cambio_total,\n",
    "            'cambio_porcentual': cambio_porcentual,\n",
    "            'tasa_cambio': tasa_cambio,\n",
    "            'rango_variacion': rango_variacion,\n",
    "            'coef_variacion': coef_variacion,\n",
    "            # Métricas de periodicidad\n",
    "            'periodo_min': periodo_min,\n",
    "            'frecuencia': frecuencia,\n",
    "            'amplitud': amplitud,\n",
    "            'regularidad': regularidad,\n",
    "            'r_cuadrado': r_cuadrado,\n",
    "            'num_picos': self._contar_picos_anomalos(datos_limpios, valor_promedio, desviacion),\n",
    "            'puntos_totales': len(datos_limpios),\n",
    "            'calidad_datos': min(1.0, len(datos_limpios) / 100)  # Métrica de calidad basada en cantidad\n",
    "        }\n",
    "        \n",
    "        return resultado_analisis\n",
    "    \n",
    "    def _clasificar_patron_temporal(self, cambio_porcentual: float, coef_variacion: float, \n",
    "                                  datos: pd.Series, promedio: float, desviacion: float) -> str:\n",
    "        \"\"\"\n",
    "        Clasificador inteligente de patrones temporales basado en análisis estadístico multi-criterio.\n",
    "        \"\"\"\n",
    "        # Umbrales adaptativos basados en coeficiente de variación\n",
    "        umbral_estabilidad = max(5, coef_variacion * 0.5)  # Adaptativo según variabilidad natural\n",
    "        umbral_cambio_significativo = max(15, coef_variacion * 1.5)\n",
    "        \n",
    "        # Análisis de anomalías estadísticas\n",
    "        picos_anomalos = self._contar_picos_anomalos(datos, promedio, desviacion)\n",
    "        porcentaje_anomalias = picos_anomalos / len(datos) * 100\n",
    "        \n",
    "        # Lógica de clasificación jerárquica\n",
    "        if porcentaje_anomalias > 10:  # Más del 10% son anomalías\n",
    "            return 'picos_anomalos'\n",
    "        elif abs(cambio_porcentual) < umbral_estabilidad and coef_variacion < 10:\n",
    "            return 'estabilidad'\n",
    "        elif cambio_porcentual > umbral_cambio_significativo:\n",
    "            return 'incremento_sostenido'\n",
    "        elif cambio_porcentual < -umbral_cambio_significativo:\n",
    "            return 'decremento_sostenido'\n",
    "        else:\n",
    "            # Verificar si hay periodicidad significativa\n",
    "            autocorr = self._calcular_autocorrelacion_simple(datos)\n",
    "            if autocorr > 0.6:  # Correlación fuerte sugiere periodicidad\n",
    "                return 'patron_ciclico'\n",
    "            else:\n",
    "                return 'estabilidad'  # Default para comportamientos no clasificables\n",
    "    \n",
    "    def _contar_picos_anomalos(self, datos: pd.Series, promedio: float, desviacion: float) -> int:\n",
    "        \"\"\"Cuenta eventos fuera de 2σ como picos anómalos.\"\"\"\n",
    "        if desviacion == 0:\n",
    "            return 0\n",
    "        umbral_superior = promedio + 2 * desviacion\n",
    "        umbral_inferior = promedio - 2 * desviacion\n",
    "        return int(((datos > umbral_superior) | (datos < umbral_inferior)).sum())\n",
    "    \n",
    "    def _analizar_periodicidad(self, datos: pd.Series) -> Tuple[float, float, float, float, float]:\n",
    "        \"\"\"\n",
    "        Análisis simplificado de periodicidad sin dependencias FFT complejas.\n",
    "        Retorna estimaciones básicas de comportamiento cíclico.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Análisis básico de autocorrelación para detectar periodicidad\n",
    "            autocorr = self._calcular_autocorrelacion_simple(datos)\n",
    "            \n",
    "            # Estimaciones simplificadas\n",
    "            periodo_estimado = len(datos) / 4  # Estimación conservadora\n",
    "            frecuencia_estimada = 1 / (periodo_estimado / 60) if periodo_estimado > 0 else 0.0\n",
    "            amplitud_estimada = (datos.max() - datos.min()) / 2\n",
    "            regularidad_estimada = min(100, autocorr * 100)\n",
    "            r_cuadrado_estimado = autocorr ** 2\n",
    "            \n",
    "            return (\n",
    "                float(periodo_estimado), float(frecuencia_estimada), \n",
    "                float(amplitud_estimada), float(regularidad_estimada),\n",
    "                float(r_cuadrado_estimado)\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error en análisis de periodicidad: {e}\")\n",
    "            return 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    \n",
    "    def _calcular_autocorrelacion_simple(self, datos: pd.Series) -> float:\n",
    "        \"\"\"Cálculo simplificado de autocorrelación lag-1.\"\"\"\n",
    "        try:\n",
    "            if len(datos) < 2:\n",
    "                return 0.0\n",
    "            correlacion = datos.corr(datos.shift(1))\n",
    "            return float(correlacion) if not pd.isna(correlacion) else 0.0\n",
    "        except:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04aba382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 13:30:12,015 - INFO - GeneradorDescripcionesTextual inicializado correctamente\n",
      "2025-10-06 13:30:12,016 - INFO - Plantillas especializadas por patrón temporal cargadas\n",
      "2025-10-06 13:30:12,016 - INFO - Plantillas especializadas por patrón temporal cargadas\n",
      "2025-10-06 13:30:12,018 - INFO - Configuraciones por red CAN establecidas\n",
      "2025-10-06 13:30:12,019 - INFO - Sistema de métricas de calidad activado\n",
      "2025-10-06 13:30:12,018 - INFO - Configuraciones por red CAN establecidas\n",
      "2025-10-06 13:30:12,019 - INFO - Sistema de métricas de calidad activado\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Motor de transformación semántica CAN→Texto listo para procesamiento\n"
     ]
    }
   ],
   "source": [
    "def generar_descripcion_señal(self, signal_name: str, serie: pd.Series, \n",
    "                                timestamps: pd.Series, red_can: str, \n",
    "                                unidad: str = \"unidad\") -> CANSignalDescription:\n",
    "    \"\"\"\n",
    "    Genera descripción textual completa para una señal CAN específica.\n",
    "    \n",
    "    Implementa el pipeline completo de transformación semántica:\n",
    "    análisis → contextualización → generación → validación\n",
    "    \n",
    "    Args:\n",
    "        signal_name: Nombre técnico de la señal CAN\n",
    "        serie: Datos temporales de la señal\n",
    "        timestamps: Marcas temporales correspondientes  \n",
    "        red_can: Red CAN de origen (CAN_EV, CAN_CATL, etc.)\n",
    "        unidad: Unidad de medida de la señal\n",
    "        \n",
    "    Returns:\n",
    "        CANSignalDescription con descripciones técnica y conversacional\n",
    "    \"\"\"\n",
    "    logger.info(f\"Generando descripción para señal: {signal_name} ({red_can})\")\n",
    "    \n",
    "    # Paso 1: Análisis estadístico avanzado de la serie temporal\n",
    "    analisis_temporal = self.analizar_serie_temporal_blf(serie, timestamps)\n",
    "    if analisis_temporal['tipo'] == 'datos_insuficientes':\n",
    "        logger.warning(f\"Análisis fallido para {signal_name}: datos insuficientes\")\n",
    "        return self._generar_descripcion_fallback(signal_name, red_can, unidad)\n",
    "    \n",
    "    # Paso 2: Selección de plantilla adaptativa basada en patrón identificado\n",
    "    patron = analisis_temporal['tipo']\n",
    "    plantillas_patron = self.plantillas_temporal.get(patron, self.plantillas_temporal['estabilidad'])\n",
    "    \n",
    "    # Selección aleatoria de plantilla para diversidad semántica\n",
    "    import random\n",
    "    plantilla_seleccionada = random.choice(plantillas_patron)\n",
    "    \n",
    "    # Paso 3: Contextualización específica por red CAN\n",
    "    contexto_red = self.plantillas_por_red.get(red_can, self.plantillas_por_red['CAN_EV'])\n",
    "    \n",
    "    # Paso 4: Generación de descripción técnica con plantilla contextualizada\n",
    "    try:\n",
    "        descripcion_tecnica = plantilla_seleccionada.format(\n",
    "            signal=signal_name,\n",
    "            unidad=unidad,\n",
    "            **analisis_temporal  # Expansión de todas las métricas calculadas\n",
    "        )\n",
    "        \n",
    "        # Enriquecimiento con contexto de red CAN\n",
    "        descripcion_tecnica = f\"{contexto_red['contexto']}, {descripcion_tecnica.lower()}\"\n",
    "        \n",
    "    except KeyError as e:\n",
    "        logger.error(f\"Error en formateo de plantilla para {signal_name}: {e}\")\n",
    "        descripcion_tecnica = self._generar_descripcion_generica(signal_name, analisis_temporal, unidad)\n",
    "    \n",
    "    # Paso 5: Generación de descripción conversacional simplificada\n",
    "    descripcion_conversacional = self._generar_descripcion_conversacional(\n",
    "        signal_name, analisis_temporal, unidad, contexto_red\n",
    "    )\n",
    "    \n",
    "    # Paso 6: Determinación de categoría semántica automática\n",
    "    categoria_semantica = self._determinar_categoria_semantica(signal_name, red_can)\n",
    "    \n",
    "    # Paso 7: Cálculo de métricas de calidad automatizadas\n",
    "    calidad_score = self._calcular_score_calidad(\n",
    "        descripcion_tecnica, descripcion_conversacional, analisis_temporal\n",
    "    )\n",
    "    \n",
    "    # Paso 8: Determinación de umbrales críticos inteligentes\n",
    "    umbrales_criticos = self._generar_umbrales_criticos(analisis_temporal, contexto_red)\n",
    "    \n",
    "    # Construcción del objeto CANSignalDescription final\n",
    "    descripcion_final = CANSignalDescription(\n",
    "        signal_name=signal_name,\n",
    "        technical_description=descripcion_tecnica,\n",
    "        conversational_description=descripcion_conversacional,\n",
    "        unit=unidad,\n",
    "        normal_range=f\"[{analisis_temporal['valor_min']:.2f}, {analisis_temporal['valor_max']:.2f}] {unidad}\",\n",
    "        critical_thresholds=umbrales_criticos,\n",
    "        semantic_category=categoria_semantica,\n",
    "        documentation_source=\"BLF_ANALYSIS\",  # Origen de datos BLF procesados\n",
    "        quality_score=calidad_score\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Descripción generada exitosamente para {signal_name} (calidad: {calidad_score:.3f})\")\n",
    "    return descripcion_final\n",
    "\n",
    "def _generar_descripcion_conversacional(self, signal_name: str, analisis: Dict, \n",
    "                                        unidad: str, contexto_red: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Genera versión conversacional accesible para usuarios no técnicos.\n",
    "    \"\"\"\n",
    "    patron = analisis['tipo']\n",
    "    valor_promedio = analisis['valor_promedio']\n",
    "    \n",
    "    # Mapeo de patrones a lenguaje conversacional\n",
    "    patrones_conversacionales = {\n",
    "        'estabilidad': f\"La señal {signal_name} se mantiene estable alrededor de {valor_promedio:.1f} {unidad} durante la operación normal del vehículo.\",\n",
    "        \n",
    "        'incremento_sostenido': f\"Se observa un aumento gradual en {signal_name} de {analisis['valor_inicial']:.1f} a {analisis['valor_final']:.1f} {unidad}, lo cual es normal durante esta fase de operación.\",\n",
    "        \n",
    "        'decremento_sostenido': f\"La señal {signal_name} disminuye controladamente desde {analisis['valor_inicial']:.1f} hasta {analisis['valor_final']:.1f} {unidad}, comportamiento esperado para esta condición operativa.\",\n",
    "        \n",
    "        'picos_anomalos': f\"Se detectaron algunos valores inusuales en {signal_name} (entre {analisis['valor_min']:.1f} y {analisis['valor_max']:.1f} {unidad}) que podrían indicar condiciones especiales de operación.\",\n",
    "        \n",
    "        'patron_ciclico': f\"La señal {signal_name} muestra un comportamiento repetitivo con valores que oscilan regularmente, típico de ciclos operacionales normales del sistema.\"\n",
    "    }\n",
    "    \n",
    "    descripcion_base = patrones_conversacionales.get(\n",
    "        patron, \n",
    "        f\"La señal {signal_name} presenta un comportamiento con valor promedio de {valor_promedio:.1f} {unidad}.\"\n",
    "    )\n",
    "    \n",
    "    # Enriquecimiento con contexto de sistema\n",
    "    sistema_contexto = {\n",
    "        'CAN_EV': \"del sistema de propulsión eléctrica\",\n",
    "        'CAN_CATL': \"del sistema de batería\",\n",
    "        'CAN_CARROC': \"de los sistemas de confort\",\n",
    "        'AUX_CHG': \"del sistema de carga\"\n",
    "    }\n",
    "    \n",
    "    contexto_sistema = sistema_contexto.get(contexto_red.get('contexto_operacional', ''), \"del vehículo\")\n",
    "    return f\"{descripcion_base} Esto forma parte {contexto_sistema}.\"\n",
    "\n",
    "def _determinar_categoria_semantica(self, signal_name: str, red_can: str) -> str:\n",
    "    \"\"\"\n",
    "    Clasifica automáticamente la señal en categorías semánticas para RAG.\n",
    "    \"\"\"\n",
    "    signal_lower = signal_name.lower()\n",
    "    \n",
    "    # Clasificación por contenido del nombre de señal\n",
    "    if any(term in signal_lower for term in ['voltaje', 'voltage', 'volt', 'v']):\n",
    "        return \"sistema_electrico\"\n",
    "    elif any(term in signal_lower for term in ['corriente', 'current', 'amp', 'a']):\n",
    "        return \"consumo_energetico\"\n",
    "    elif any(term in signal_lower for term in ['temperatura', 'temp', 'celsius', 'c']):\n",
    "        return \"gestion_termica\"\n",
    "    elif any(term in signal_lower for term in ['rpm', 'velocidad', 'speed']):\n",
    "        return \"control_motor\"\n",
    "    elif any(term in signal_lower for term in ['soc', 'carga', 'charge', '%']):\n",
    "        return \"gestion_bateria\"\n",
    "    elif any(term in signal_lower for term in ['puerta', 'door', 'luz', 'light']):\n",
    "        return \"sistemas_confort\"\n",
    "    elif any(term in signal_lower for term in ['error', 'fault', 'dtc', 'diag']):\n",
    "        return \"diagnostico\"\n",
    "    else:\n",
    "        # Clasificación por red CAN como fallback\n",
    "        categorias_red = {\n",
    "            'CAN_EV': 'control_motor',\n",
    "            'CAN_CATL': 'gestion_bateria', \n",
    "            'CAN_CARROC': 'sistemas_confort',\n",
    "            'AUX_CHG': 'sistema_carga'\n",
    "        }\n",
    "        return categorias_red.get(red_can, 'sistema_general')\n",
    "\n",
    "def _generar_umbrales_criticos(self, analisis: Dict, contexto_red: Dict) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Genera umbrales críticos inteligentes basados en análisis estadístico.\n",
    "    \"\"\"\n",
    "    promedio = analisis['valor_promedio']\n",
    "    desviacion = analisis['desviacion']\n",
    "    valor_min = analisis['valor_min']\n",
    "    valor_max = analisis['valor_max']\n",
    "    \n",
    "    # Umbrales adaptativos basados en la criticidad del sistema\n",
    "    criticidad = contexto_red.get('criticidad', 'media')\n",
    "    \n",
    "    if criticidad == 'crítica':  # Ej: batería\n",
    "        factor_warning = 1.5\n",
    "        factor_critical = 2.0\n",
    "    elif criticidad == 'alta':   # Ej: propulsión\n",
    "        factor_warning = 2.0\n",
    "        factor_critical = 2.5\n",
    "    else:  # media o baja\n",
    "        factor_warning = 2.5\n",
    "        factor_critical = 3.0\n",
    "    \n",
    "    return {\n",
    "        'warning_low': max(valor_min, promedio - factor_warning * desviacion),\n",
    "        'warning_high': min(valor_max, promedio + factor_warning * desviacion),\n",
    "        'critical_low': max(valor_min, promedio - factor_critical * desviacion),\n",
    "        'critical_high': min(valor_max, promedio + factor_critical * desviacion),\n",
    "        'absolute_min': valor_min,\n",
    "        'absolute_max': valor_max,\n",
    "        'nominal': promedio\n",
    "    }\n",
    "\n",
    "def _calcular_score_calidad(self, desc_tecnica: str, desc_conversacional: str, \n",
    "                            analisis: Dict) -> float:\n",
    "    \"\"\"\n",
    "    Calcula score de calidad automatizado para la descripción generada.\n",
    "    \"\"\"\n",
    "    score_componentes = []\n",
    "    \n",
    "    # 1. Completitud de información (0-1)\n",
    "    campos_requeridos = ['valor_promedio', 'desviacion', 'valor_min', 'valor_max']\n",
    "    completitud = sum(1 for campo in campos_requeridos if campo in analisis) / len(campos_requeridos)\n",
    "    score_componentes.append(completitud)\n",
    "    \n",
    "    # 2. Longitud apropiada de descripción (0-1)\n",
    "    longitud_tecnica = len(desc_tecnica.split())\n",
    "    longitud_conversacional = len(desc_conversacional.split())\n",
    "    score_longitud = min(1.0, (longitud_tecnica + longitud_conversacional) / 50)  # Optimal ~25 words each\n",
    "    score_componentes.append(score_longitud)\n",
    "    \n",
    "    # 3. Precisión numérica (basada en calidad de datos)\n",
    "    calidad_datos = analisis.get('calidad_datos', 0.5)\n",
    "    score_componentes.append(calidad_datos)\n",
    "    \n",
    "    # 4. Diversidad semántica (basada en variedad de métricas)\n",
    "    metricas_incluidas = len([k for k in analisis.keys() if isinstance(analisis[k], (int, float))])\n",
    "    diversidad = min(1.0, metricas_incluidas / 15)  # ~15 métricas disponibles\n",
    "    score_componentes.append(diversidad)\n",
    "    \n",
    "    # Score final ponderado\n",
    "    return sum(score_componentes) / len(score_componentes)\n",
    "\n",
    "def _generar_descripcion_fallback(self, signal_name: str, red_can: str, unidad: str) -> CANSignalDescription:\n",
    "    \"\"\"\n",
    "    Genera descripción básica para casos con datos insuficientes.\n",
    "    \"\"\"\n",
    "    return CANSignalDescription(\n",
    "        signal_name=signal_name,\n",
    "        technical_description=f\"Señal {signal_name} de la red {red_can} con datos insuficientes para análisis temporal detallado.\",\n",
    "        conversational_description=f\"La señal {signal_name} requiere más datos para generar una descripción completa.\",\n",
    "        unit=unidad,\n",
    "        normal_range=\"No determinado\",\n",
    "        critical_thresholds={},\n",
    "        semantic_category=self._determinar_categoria_semantica(signal_name, red_can),\n",
    "        documentation_source=\"INSUFFICIENT_DATA\",\n",
    "        quality_score=0.1\n",
    "    )\n",
    "\n",
    "def _generar_descripcion_generica(self, signal_name: str, analisis: Dict, unidad: str) -> str:\n",
    "    \"\"\"\n",
    "    Genera descripción genérica cuando fallan las plantillas especializadas.\n",
    "    \"\"\"\n",
    "    return (f\"La señal {signal_name} presenta un valor promedio de {analisis['valor_promedio']:.2f} {unidad} \"\n",
    "            f\"con desviación estándar de {analisis['desviacion']:.3f} {unidad} durante el período analizado.\")\n",
    "\n",
    "# Inicialización del generador con logging\n",
    "generador_descripciones = GeneradorDescripcionesTextual()\n",
    "logger.info(\"GeneradorDescripcionesTextual inicializado correctamente\")\n",
    "logger.info(\"Plantillas especializadas por patrón temporal cargadas\")\n",
    "logger.info(\"Configuraciones por red CAN establecidas\") \n",
    "logger.info(\"Sistema de métricas de calidad activado\")\n",
    "print(\"\\n Motor de transformación semántica CAN→Texto listo para procesamiento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2583964d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADVERTENCIA: No se han seleccionado archivos BLF\n",
      "Ejecutando con datos simulados para demostración...\n",
      "Generando descripciones textuales desde logs BLF procesados...\n",
      "\n",
      "Procesando CAN_EV...\n",
      "  Error procesando CAN_EV: 'GeneradorDescripcionesTextual' object has no attribute 'generar_descripcion_señal'\n",
      "Procesando CAN_CATL...\n",
      "  Error procesando CAN_CATL: 'GeneradorDescripcionesTextual' object has no attribute 'generar_descripcion_señal'\n",
      "\n",
      "Total de redes procesadas: 0\n",
      "\n",
      "--- EJEMPLOS DE DESCRIPCIONES GENERADAS ---\n",
      "\n",
      "Descripciones textuales listas para construcción de dataset RAG\n",
      "Generando descripciones textuales desde logs BLF procesados...\n",
      "\n",
      "Procesando CAN_EV...\n",
      "  Error procesando CAN_EV: 'GeneradorDescripcionesTextual' object has no attribute 'generar_descripcion_señal'\n",
      "Procesando CAN_CATL...\n",
      "  Error procesando CAN_CATL: 'GeneradorDescripcionesTextual' object has no attribute 'generar_descripcion_señal'\n",
      "\n",
      "Total de redes procesadas: 0\n",
      "\n",
      "--- EJEMPLOS DE DESCRIPCIONES GENERADAS ---\n",
      "\n",
      "Descripciones textuales listas para construcción de dataset RAG\n"
     ]
    }
   ],
   "source": [
    "# Agregar el método faltante a la clase GeneradorDescripcionesTextual\n",
    "def procesar_dataset_completo(self, df: pd.DataFrame, red_can: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Se procesa un dataset CAN y se generan descripciones para todas las señales\n",
    "    \"\"\"\n",
    "    descripciones = []\n",
    "    \n",
    "    # Identificar columna de timestamps\n",
    "    columna_tiempo = None\n",
    "    for col in ['timestamp', 'time', 'tiempo', 'Time']:\n",
    "        if col in df.columns:\n",
    "            columna_tiempo = col\n",
    "            break\n",
    "\n",
    "    if columna_tiempo is None:\n",
    "        print(f\"Advertencia: No se encontró columna de tiempo en {red_can}\")\n",
    "        timestamps = pd.Series(range(len(df)))  # Uso de indices como fallback\n",
    "    else:\n",
    "        timestamps = df[columna_tiempo]\n",
    "        \n",
    "    # Procesar cada señal numérica\n",
    "    senales_numericas = df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for signal in senales_numericas:\n",
    "        if signal != columna_tiempo:  # Excluir timestamp del análisis\n",
    "            # Usar el método que existe en la clase\n",
    "            descripcion_obj = self.generar_descripcion_señal(\n",
    "                signal, df[signal], timestamps, red_can\n",
    "            )\n",
    "            # Extraer la descripción técnica del objeto retornado\n",
    "            descripciones.append(descripcion_obj.technical_description)\n",
    "    \n",
    "    # Agregar resumen del dataset\n",
    "    num_signals = len(senales_numericas) - (1 if columna_tiempo in senales_numericas else 0)\n",
    "    duracion_total = len(df)\n",
    "    resumen = f\"El dataset {red_can} contiene {num_signals} señales monitoreadas durante {duracion_total} puntos temporales extraídos de logs BLF del vehículo en operación real.\"\n",
    "    descripciones.append(resumen)\n",
    "    \n",
    "    return descripciones\n",
    "\n",
    "# Agregar el método a la clase existente\n",
    "GeneradorDescripcionesTextual.procesar_dataset_completo = procesar_dataset_completo\n",
    "\n",
    "# === EJECUCIÓN PARA GENERAR DESCRIPCIONES ===\n",
    "\n",
    "# Primero verificar que tenemos los datos necesarios\n",
    "if 'archivos_blf' not in locals() or not archivos_blf:\n",
    "    print(\"ADVERTENCIA: No se han seleccionado archivos BLF\")\n",
    "    print(\"Ejecutando con datos simulados para demostración...\")\n",
    "    \n",
    "    # Crear datos simulados\n",
    "    datos_can = {\n",
    "        'CAN_EV': pd.DataFrame({\n",
    "            'timestamp': pd.date_range('2024-01-01', periods=100, freq='1S'),\n",
    "            'Velocidad_Motor_RPM': np.random.normal(1500, 300, 100),\n",
    "            'Torque_Motor_Nm': np.random.normal(200, 50, 100),\n",
    "            'Temperatura_Motor_C': np.random.normal(45, 10, 100)\n",
    "        }),\n",
    "        'CAN_CATL': pd.DataFrame({\n",
    "            'timestamp': pd.date_range('2024-01-01', periods=100, freq='1S'),\n",
    "            'SOC_Porcentaje': np.random.uniform(20, 100, 100),\n",
    "            'Voltaje_Bateria_V': np.random.normal(400, 20, 100)\n",
    "        })\n",
    "    }\n",
    "else:\n",
    "    # Cargar datos reales si están disponibles\n",
    "    try:\n",
    "        datos_can = cargar_datos_blf_con_dbc(archivos_blf, definiciones_dbc)\n",
    "    except Exception as e:\n",
    "        print(f\"Error cargando datos reales: {e}\")\n",
    "        print(\"Usando datos simulados...\")\n",
    "        datos_can = {\n",
    "            'CAN_EV': pd.DataFrame({\n",
    "                'timestamp': pd.date_range('2024-01-01', periods=100, freq='1S'),\n",
    "                'Velocidad_Motor_RPM': np.random.normal(1500, 300, 100),\n",
    "                'Torque_Motor_Nm': np.random.normal(200, 50, 100)\n",
    "            })\n",
    "        }\n",
    "\n",
    "# Instanciar generador de descripciones textuales\n",
    "generador_textual = GeneradorDescripcionesTextual()\n",
    "\n",
    "# Generar descripciones para cada red CAN\n",
    "descripciones_por_red = {}\n",
    "\n",
    "print(\"Generando descripciones textuales desde logs BLF procesados...\\n\")\n",
    "\n",
    "for nombre_red, df in datos_can.items():\n",
    "    if not df.empty:\n",
    "        print(f\"Procesando {nombre_red}...\")\n",
    "        try:\n",
    "            descripciones = generador_textual.procesar_dataset_completo(df, nombre_red)\n",
    "            descripciones_por_red[nombre_red] = descripciones\n",
    "            print(f\"  {len(descripciones)} descripciones generadas\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error procesando {nombre_red}: {e}\")\n",
    "            continue\n",
    "    else:\n",
    "        print(f\"Saltando {nombre_red} (dataset vacío)\")\n",
    "\n",
    "print(f\"\\nTotal de redes procesadas: {len(descripciones_por_red)}\")\n",
    "\n",
    "# Mostrar ejemplos\n",
    "print(\"\\n--- EJEMPLOS DE DESCRIPCIONES GENERADAS ---\")\n",
    "for red, descripciones in descripciones_por_red.items():\n",
    "    if descripciones:\n",
    "        print(f\"\\n{red} (muestra):\")\n",
    "        print(f\"  {descripciones[0]}\")\n",
    "        if len(descripciones) > 1:\n",
    "            print(f\"  {descripciones[1]}\")\n",
    "            \n",
    "print(\"\\nDescripciones textuales listas para construcción de dataset RAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c1c51ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métodos disponibles en GeneradorDescripcionesTextual:\n",
      "  - analizar_serie_temporal_blf\n",
      "  - metricas_calidad\n",
      "  - plantillas_por_red\n",
      "  - plantillas_temporal\n",
      "  - procesar_dataset_completo\n",
      "\n",
      "¿Tiene generar_descripcion_señal? False\n",
      "¿Tiene generar_descripcion_signal? False\n",
      "\n",
      "Métodos que contienen 'generar': []\n"
     ]
    }
   ],
   "source": [
    "# Verificar qué métodos tiene la clase GeneradorDescripcionesTextual\n",
    "print(\"Métodos disponibles en GeneradorDescripcionesTextual:\")\n",
    "for metodo in dir(generador_textual):\n",
    "    if not metodo.startswith('_'):\n",
    "        print(f\"  - {metodo}\")\n",
    "\n",
    "# Verificar si el método generar_descripcion_señal existe\n",
    "print(f\"\\n¿Tiene generar_descripcion_señal? {hasattr(generador_textual, 'generar_descripcion_señal')}\")\n",
    "print(f\"¿Tiene generar_descripcion_signal? {hasattr(generador_textual, 'generar_descripcion_signal')}\")\n",
    "\n",
    "# Buscar métodos similares\n",
    "metodos_generar = [m for m in dir(generador_textual) if 'generar' in m.lower()]\n",
    "print(f\"\\nMétodos que contienen 'generar': {metodos_generar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af340a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Método generar_descripcion_señal agregado correctamente a la clase\n",
      "¿Ahora tiene generar_descripcion_señal? True\n"
     ]
    }
   ],
   "source": [
    "# Definir e implementar el método generar_descripcion_señal que falta\n",
    "def generar_descripcion_señal(self, signal_name: str, serie: pd.Series, \n",
    "                             timestamps: pd.Series, red_can: str, \n",
    "                             unidad: str = \"unidad\"):\n",
    "    \"\"\"\n",
    "    Genera descripción textual completa para una señal CAN específica.\n",
    "    \n",
    "    Args:\n",
    "        signal_name: Nombre técnico de la señal CAN\n",
    "        serie: Datos temporales de la señal\n",
    "        timestamps: Marcas temporales correspondientes  \n",
    "        red_can: Red CAN de origen (CAN_EV, CAN_CATL, etc.)\n",
    "        unidad: Unidad de medida de la señal\n",
    "        \n",
    "    Returns:\n",
    "        Objeto con descripción técnica y conversacional\n",
    "    \"\"\"\n",
    "    \n",
    "    # Análisis estadístico de la serie temporal\n",
    "    analisis_temporal = self.analizar_serie_temporal_blf(serie, timestamps)\n",
    "    \n",
    "    # Si no hay datos suficientes, generar descripción básica\n",
    "    if analisis_temporal['tipo'] == 'datos_insuficientes':\n",
    "        return type('CANSignalDescription', (), {\n",
    "            'technical_description': f\"Señal {signal_name} de la red {red_can} con datos insuficientes para análisis detallado.\",\n",
    "            'conversational_description': f\"La señal {signal_name} requiere más datos para generar una descripción completa.\",\n",
    "            'signal_name': signal_name,\n",
    "            'unit': unidad,\n",
    "            'normal_range': \"No determinado\",\n",
    "            'critical_thresholds': {},\n",
    "            'semantic_category': \"general\",\n",
    "            'documentation_source': \"INSUFFICIENT_DATA\",\n",
    "            'quality_score': 0.1\n",
    "        })()\n",
    "    \n",
    "    # Seleccionar plantilla basada en el patrón identificado\n",
    "    patron = analisis_temporal['tipo']\n",
    "    plantillas_patron = self.plantillas_temporal.get(patron, self.plantillas_temporal['estabilidad'])\n",
    "    \n",
    "    import random\n",
    "    plantilla_seleccionada = random.choice(plantillas_patron)\n",
    "    \n",
    "    # Contextualización específica por red CAN\n",
    "    contexto_red = self.plantillas_por_red.get(red_can, self.plantillas_por_red['CAN_EV'])\n",
    "    \n",
    "    # Generar descripción técnica\n",
    "    try:\n",
    "        descripcion_tecnica = plantilla_seleccionada.format(\n",
    "            signal=signal_name,\n",
    "            unidad=unidad,\n",
    "            **analisis_temporal\n",
    "        )\n",
    "        descripcion_tecnica = f\"{contexto_red['contexto']}, {descripcion_tecnica.lower()}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error formateando plantilla para {signal_name}: {e}\")\n",
    "        descripcion_tecnica = f\"La señal {signal_name} presenta un valor promedio de {analisis_temporal['valor_promedio']:.2f} {unidad} con desviación estándar de {analisis_temporal['desviacion']:.3f} {unidad} durante el período analizado.\"\n",
    "    \n",
    "    # Generar descripción conversacional\n",
    "    patron_conversacional = {\n",
    "        'estabilidad': f\"La señal {signal_name} se mantiene estable alrededor de {analisis_temporal['valor_promedio']:.1f} {unidad}.\",\n",
    "        'incremento_sostenido': f\"Se observa un aumento gradual en {signal_name} de {analisis_temporal['valor_inicial']:.1f} a {analisis_temporal['valor_final']:.1f} {unidad}.\",\n",
    "        'decremento_sostenido': f\"La señal {signal_name} disminuye controladamente desde {analisis_temporal['valor_inicial']:.1f} hasta {analisis_temporal['valor_final']:.1f} {unidad}.\",\n",
    "        'picos_anomalos': f\"Se detectaron algunos valores inusuales en {signal_name} (entre {analisis_temporal['valor_min']:.1f} y {analisis_temporal['valor_max']:.1f} {unidad}).\",\n",
    "        'patron_ciclico': f\"La señal {signal_name} muestra un comportamiento repetitivo con valores que oscilan regularmente.\"\n",
    "    }\n",
    "    \n",
    "    descripcion_conversacional = patron_conversacional.get(\n",
    "        patron, \n",
    "        f\"La señal {signal_name} presenta un comportamiento con valor promedio de {analisis_temporal['valor_promedio']:.1f} {unidad}.\"\n",
    "    )\n",
    "    \n",
    "    # Crear y retornar el objeto de descripción\n",
    "    return type('CANSignalDescription', (), {\n",
    "        'technical_description': descripcion_tecnica,\n",
    "        'conversational_description': descripcion_conversacional,\n",
    "        'signal_name': signal_name,\n",
    "        'unit': unidad,\n",
    "        'normal_range': f\"[{analisis_temporal['valor_min']:.2f}, {analisis_temporal['valor_max']:.2f}] {unidad}\",\n",
    "        'critical_thresholds': {\n",
    "            'warning_low': analisis_temporal['valor_promedio'] - 2 * analisis_temporal['desviacion'],\n",
    "            'warning_high': analisis_temporal['valor_promedio'] + 2 * analisis_temporal['desviacion']\n",
    "        },\n",
    "        'semantic_category': \"general\",\n",
    "        'documentation_source': \"BLF_ANALYSIS\",\n",
    "        'quality_score': 0.8\n",
    "    })()\n",
    "\n",
    "# Agregar el método a la clase\n",
    "GeneradorDescripcionesTextual.generar_descripcion_señal = generar_descripcion_señal\n",
    "\n",
    "print(\"Método generar_descripcion_señal agregado correctamente a la clase\")\n",
    "print(f\"¿Ahora tiene generar_descripcion_señal? {hasattr(generador_textual, 'generar_descripcion_señal')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
